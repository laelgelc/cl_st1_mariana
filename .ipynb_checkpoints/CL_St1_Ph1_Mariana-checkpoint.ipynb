{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 1 - Mariana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ad8a7-2d34-476b-be69-5d896b27d3ed",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1209cf-0515-45b3-8856-275ac692943e",
   "metadata": {},
   "source": [
    "Make sure the prerequisites in [CL_LMDA_prerequisites](https://github.com/laelgelc/laelgelc/blob/main/CL_LMDA_prerequisites.ipynb) are satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28897518-a858-4dc5-b510-49c9131da966",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f58941-1578-42c0-8933-d8ebef369245",
   "metadata": {},
   "source": [
    "Please download the following dataset (Right-click on the link and choose `Open link in a new tab` to download the corresponding file):\n",
    "- [mari2016_2022_pt.jsonl](https://pucsp-my.sharepoint.com/:u:/g/personal/ra00341729_pucsp_edu_br/EfSI2XLs9AlKqSkqJUW8TNIBEd_gXpNgxQX7qb7XI7T8Mw?e=iMGZTD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c2af7-9fc1-4f51-a4f5-2ed915b93039",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6689499-d19d-4b0c-befd-f88926b7105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import demoji\n",
    "import re\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a79a002-c182-4021-9b77-99ad470582af",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e37aae-8cee-42ca-91ff-10f882fc45c6",
   "metadata": {},
   "source": [
    "### Importing the tweet raw data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a762708-07e4-472d-b3e9-bb0cea14438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_raw_data = pd.read_json('mari2016_2022_pt.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623ddacd-5a20-4d89-a48e-98849a0644e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-03 15:00:41</td>\n",
       "      <td>1090552219</td>\n",
       "      <td>PopSeriesBrasil</td>\n",
       "      <td>https://twitter.com/PopSeriesBrasil/status/782...</td>\n",
       "      <td>Sheldon com problemas no novo epis√≥dio de #TBB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-03 15:00:54</td>\n",
       "      <td>2955241713</td>\n",
       "      <td>crl_jana</td>\n",
       "      <td>https://twitter.com/crl_jana/status/7829586130...</td>\n",
       "      <td>\"Pra vcs, qual a causa de viol√™ncia?\" \"inveja ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-30 15:00:02</td>\n",
       "      <td>324548290</td>\n",
       "      <td>pxthifraga_</td>\n",
       "      <td>https://twitter.com/pxthifraga_/status/7927428...</td>\n",
       "      <td>Fui votar e esqueci a identidade,j√° tava no me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-13 15:20:17</td>\n",
       "      <td>2751208197</td>\n",
       "      <td>heeyvasques</td>\n",
       "      <td>https://twitter.com/heeyvasques/status/7865873...</td>\n",
       "      <td>pare√ßo at√© stalker da isabella mas n√£o sou nao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-13 15:20:25</td>\n",
       "      <td>4158067325</td>\n",
       "      <td>Fuckinshadyy</td>\n",
       "      <td>https://twitter.com/Fuckinshadyy/status/786587...</td>\n",
       "      <td>oi crian√ßas, voc√™s gostam de viol√™ncia?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at   author_id         username  \\\n",
       "0 2016-10-03 15:00:41  1090552219  PopSeriesBrasil   \n",
       "1 2016-10-03 15:00:54  2955241713         crl_jana   \n",
       "2 2016-10-30 15:00:02   324548290      pxthifraga_   \n",
       "3 2016-10-13 15:20:17  2751208197      heeyvasques   \n",
       "4 2016-10-13 15:20:25  4158067325     Fuckinshadyy   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0  https://twitter.com/PopSeriesBrasil/status/782...   \n",
       "1  https://twitter.com/crl_jana/status/7829586130...   \n",
       "2  https://twitter.com/pxthifraga_/status/7927428...   \n",
       "3  https://twitter.com/heeyvasques/status/7865873...   \n",
       "4  https://twitter.com/Fuckinshadyy/status/786587...   \n",
       "\n",
       "                                                text  \n",
       "0  Sheldon com problemas no novo epis√≥dio de #TBB...  \n",
       "1  \"Pra vcs, qual a causa de viol√™ncia?\" \"inveja ...  \n",
       "2  Fui votar e esqueci a identidade,j√° tava no me...  \n",
       "3  pare√ßo at√© stalker da isabella mas n√£o sou nao...  \n",
       "4            oi crian√ßas, voc√™s gostam de viol√™ncia?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e11cf2-cb39-49ee-a601-58a4ec3caa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5409904, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bd2975-f291-4fdb-9c2f-51dd6b8c269d",
   "metadata": {},
   "source": [
    "#### Inspecting a few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6109d2f2-4cd1-43ce-86fe-7fb7f1ff8910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username:crl_jana\n",
      "text:\"Pra vcs, qual a causa de viol√™ncia?\" \"inveja professor\" üòÇüòÇüòÇ\n",
      "tweet_url:https://twitter.com/crl_jana/status/782958613010800640\n"
     ]
    }
   ],
   "source": [
    "inspected_row = 1\n",
    "print('username:' + df_tweets_raw_data.loc[inspected_row, 'username'])\n",
    "print('text:' + df_tweets_raw_data.loc[inspected_row, 'text'])\n",
    "print('tweet_url:' + df_tweets_raw_data.loc[inspected_row, 'tweet_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277d732-f65b-4e0c-868d-16d2d38ef04b",
   "metadata": {},
   "source": [
    "### Inspecting the dataset and eliminating malformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a369a-af13-45f0-99b2-6ce5b6388a1c",
   "metadata": {},
   "source": [
    "#### Checking if data types are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6795c314-cc1f-4acd-86a1-a4eada8a9bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at    datetime64[ns]\n",
       "author_id              int64\n",
       "username              object\n",
       "tweet_url             object\n",
       "text                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30643060-8eaa-47e0-9a52-95f6fbd75515",
   "metadata": {},
   "source": [
    "#### Identifying rows that are empty in column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6de7bb2-56d3-41cb-9294-d19dbeca836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_tweets_raw_data['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9e9cf4-0f39-4cdc-84f0-84d8446eea53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_at, author_id, username, tweet_url, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data[df_tweets_raw_data['text'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc61e-77c5-4339-99ed-e8aea3a1ec42",
   "metadata": {},
   "source": [
    "#### Dropping the rows that are empty in the column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db62e8de-5e85-4474-9bf4-4c9342c2640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows whose column 'text' is NaN\n",
    "df_tweets_raw_data = df_tweets_raw_data.dropna(subset=['text'])\n",
    "\n",
    "# Reset the index\n",
    "df_tweets_raw_data = df_tweets_raw_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44d9a76-464b-41ca-842a-921beae1c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_tweets_raw_data['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd59c55-0719-4485-ad8c-2f76fc5b21ee",
   "metadata": {},
   "source": [
    "#### Removing specific Unicode characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cc0ca-8a41-4c78-a341-3622a22244a5",
   "metadata": {},
   "source": [
    "The dataset may need to be cleaned of invisible Unicode characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93248ba8-48c5-466a-ac42-f51705ecdf91",
   "metadata": {},
   "source": [
    "##### Detecting `U+2066` and `U+2069` characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7838b4-b5dd-4a45-ae3a-e4f3f8408a2b",
   "metadata": {},
   "source": [
    "- [U+2066](https://www.compart.com/en/unicode/U+2066)\n",
    "- [U+2069](https://www.compart.com/en/unicode/U+2069)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1feac56-081a-4197-85ec-363a958848fb",
   "metadata": {},
   "source": [
    "Please refer to:\n",
    "- [Python RegEx](https://www.w3schools.com/python/python_regex.asp)\n",
    "- [regex101](https://regex101.com/)\n",
    "- [RegExr](https://regexr.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "569db1bb-d6ee-4eca-8383-5dfb522f35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character ‚Å¶: Count = 1436\n",
      "Character ‚Å©: Count = 1279\n"
     ]
    }
   ],
   "source": [
    "# Defining a function to detect specific Unicode characters\n",
    "def extract_unicode_characters(df, column_name):\n",
    "    unicode_chars = Counter()  # Initialize a Counter to store Unicode character counts\n",
    "\n",
    "    for value in df[column_name]:\n",
    "        if isinstance(value, str):\n",
    "            # Use RegEx to find non-ASCII characters (Unicode)\n",
    "#            non_ascii_chars = re.findall(r'[^\\x00-\\x7F]+', value)\n",
    "            # Use RegEx to find specific Unicode characters - adjust the expression accordingly\n",
    "            specific_unicode_chars = re.findall(r'[\\u2066\\u2069]', value)\n",
    "            unicode_chars.update(specific_unicode_chars)\n",
    "\n",
    "    return unicode_chars\n",
    "\n",
    "# Inspect the dataframe for specific Unicode characters\n",
    "unicode_counts = extract_unicode_characters(df_tweets_raw_data, 'text')\n",
    "\n",
    "# Print the results\n",
    "for char, count in unicode_counts.items():\n",
    "    print(f'Character {char}: Count = {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3a43b-31d1-47d2-8bc3-c701c5450b3a",
   "metadata": {},
   "source": [
    "##### Removing `U+2066` and `U+2069` characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "795d7929-bb59-4417-87e5-1448a3662264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to remove specific Unicode characters\n",
    "def remove_specific_unicode(input_line):\n",
    "    # Using RegEx to replace specific Unicode characters - adjust the expression accordingly\n",
    "    cleaned_line = re.sub(r'[\\u2066\\u2069]', '', input_line)\n",
    "    return cleaned_line\n",
    "\n",
    "# Removing specific Unicode characters\n",
    "df_tweets_raw_data['text'] = df_tweets_raw_data['text'].apply(remove_specific_unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f8843a-adfd-416f-bed9-f1380775e7bd",
   "metadata": {},
   "source": [
    "#### Replacing the `LF` character by a space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8176756-2994-4a83-b77e-3d5dec420463",
   "metadata": {},
   "source": [
    "Some tweets, especially the retweeted ones, contain multiple lines of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "566a880a-7a43-4438-9455-36d5083678c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace the `LF` character by a space\n",
    "def remove_cr_lf(input_line):\n",
    "    # Using RegEx to replace LF by a space\n",
    "    cleaned_line = re.sub(r'\\n', ' ', input_line)\n",
    "    return cleaned_line\n",
    "\n",
    "# Applying the function to the 'text' column in your DataFrame\n",
    "df_tweets_raw_data['text'] = df_tweets_raw_data['text'].apply(remove_cr_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aab4c8c-48b5-4f60-9a3e-1c19981ece20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-03 15:00:41</td>\n",
       "      <td>1090552219</td>\n",
       "      <td>PopSeriesBrasil</td>\n",
       "      <td>https://twitter.com/PopSeriesBrasil/status/782...</td>\n",
       "      <td>Sheldon com problemas no novo epis√≥dio de #TBB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-03 15:00:54</td>\n",
       "      <td>2955241713</td>\n",
       "      <td>crl_jana</td>\n",
       "      <td>https://twitter.com/crl_jana/status/7829586130...</td>\n",
       "      <td>\"Pra vcs, qual a causa de viol√™ncia?\" \"inveja ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-30 15:00:02</td>\n",
       "      <td>324548290</td>\n",
       "      <td>pxthifraga_</td>\n",
       "      <td>https://twitter.com/pxthifraga_/status/7927428...</td>\n",
       "      <td>Fui votar e esqueci a identidade,j√° tava no me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-13 15:20:17</td>\n",
       "      <td>2751208197</td>\n",
       "      <td>heeyvasques</td>\n",
       "      <td>https://twitter.com/heeyvasques/status/7865873...</td>\n",
       "      <td>pare√ßo at√© stalker da isabella mas n√£o sou nao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-13 15:20:25</td>\n",
       "      <td>4158067325</td>\n",
       "      <td>Fuckinshadyy</td>\n",
       "      <td>https://twitter.com/Fuckinshadyy/status/786587...</td>\n",
       "      <td>oi crian√ßas, voc√™s gostam de viol√™ncia?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409899</th>\n",
       "      <td>2022-09-21 17:46:51</td>\n",
       "      <td>1571649879302176768</td>\n",
       "      <td>ely_amaislinda</td>\n",
       "      <td>https://twitter.com/ely_amaislinda/status/1572...</td>\n",
       "      <td>RT @isahmkkj: botar o fone no m√°ximo pra n√£o l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409900</th>\n",
       "      <td>2022-09-07 21:53:44</td>\n",
       "      <td>163277866</td>\n",
       "      <td>andrepreis</td>\n",
       "      <td>https://twitter.com/andrepreis/status/15676322...</td>\n",
       "      <td>@bernardokuster2 O maior problema √© q os votos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409901</th>\n",
       "      <td>2022-09-13 20:03:13</td>\n",
       "      <td>1023955089604657152</td>\n",
       "      <td>MenecasAlda</td>\n",
       "      <td>https://twitter.com/MenecasAlda/status/1569778...</td>\n",
       "      <td>RT @Joaquim63301491: @LulaOficial @rai10oficia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409902</th>\n",
       "      <td>2022-09-22 19:27:51</td>\n",
       "      <td>1091197495458308096</td>\n",
       "      <td>Danizinha4321</td>\n",
       "      <td>https://twitter.com/Danizinha4321/status/15730...</td>\n",
       "      <td>RT @bibiperigosaa7_: iludida √© a mulher que ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409903</th>\n",
       "      <td>2022-09-06 18:12:49</td>\n",
       "      <td>1290627563648425984</td>\n",
       "      <td>mafair12</td>\n",
       "      <td>https://twitter.com/mafair12/status/1567214251...</td>\n",
       "      <td>RT @MinLuizRamos: ‚ÄúVamos preservar o que DEUS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5409904 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at            author_id         username  \\\n",
       "0       2016-10-03 15:00:41           1090552219  PopSeriesBrasil   \n",
       "1       2016-10-03 15:00:54           2955241713         crl_jana   \n",
       "2       2016-10-30 15:00:02            324548290      pxthifraga_   \n",
       "3       2016-10-13 15:20:17           2751208197      heeyvasques   \n",
       "4       2016-10-13 15:20:25           4158067325     Fuckinshadyy   \n",
       "...                     ...                  ...              ...   \n",
       "5409899 2022-09-21 17:46:51  1571649879302176768   ely_amaislinda   \n",
       "5409900 2022-09-07 21:53:44            163277866       andrepreis   \n",
       "5409901 2022-09-13 20:03:13  1023955089604657152      MenecasAlda   \n",
       "5409902 2022-09-22 19:27:51  1091197495458308096    Danizinha4321   \n",
       "5409903 2022-09-06 18:12:49  1290627563648425984         mafair12   \n",
       "\n",
       "                                                 tweet_url  \\\n",
       "0        https://twitter.com/PopSeriesBrasil/status/782...   \n",
       "1        https://twitter.com/crl_jana/status/7829586130...   \n",
       "2        https://twitter.com/pxthifraga_/status/7927428...   \n",
       "3        https://twitter.com/heeyvasques/status/7865873...   \n",
       "4        https://twitter.com/Fuckinshadyy/status/786587...   \n",
       "...                                                    ...   \n",
       "5409899  https://twitter.com/ely_amaislinda/status/1572...   \n",
       "5409900  https://twitter.com/andrepreis/status/15676322...   \n",
       "5409901  https://twitter.com/MenecasAlda/status/1569778...   \n",
       "5409902  https://twitter.com/Danizinha4321/status/15730...   \n",
       "5409903  https://twitter.com/mafair12/status/1567214251...   \n",
       "\n",
       "                                                      text  \n",
       "0        Sheldon com problemas no novo epis√≥dio de #TBB...  \n",
       "1        \"Pra vcs, qual a causa de viol√™ncia?\" \"inveja ...  \n",
       "2        Fui votar e esqueci a identidade,j√° tava no me...  \n",
       "3        pare√ßo at√© stalker da isabella mas n√£o sou nao...  \n",
       "4                  oi crian√ßas, voc√™s gostam de viol√™ncia?  \n",
       "...                                                    ...  \n",
       "5409899  RT @isahmkkj: botar o fone no m√°ximo pra n√£o l...  \n",
       "5409900  @bernardokuster2 O maior problema √© q os votos...  \n",
       "5409901  RT @Joaquim63301491: @LulaOficial @rai10oficia...  \n",
       "5409902  RT @bibiperigosaa7_: iludida √© a mulher que ac...  \n",
       "5409903  RT @MinLuizRamos: ‚ÄúVamos preservar o que DEUS ...  \n",
       "\n",
       "[5409904 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c87ca3-d26d-450c-8a8e-669a3bc51afb",
   "metadata": {},
   "source": [
    "### Dropping duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eee4c7-06e1-4ac6-9fd6-0080e0aa3403",
   "metadata": {},
   "source": [
    "#### Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a7b99f-669d-486a-a247-820c7066c45f",
   "metadata": {},
   "source": [
    "Retweets bear the RegEx pattern `'\\bRT @\\w+\\s*:'gm` or `'\\bRT @\\w+\\s':\"gm` at the beginning of the column `text`. They should be often dropped because they are duplicates of the original tweets. In the case of this study, though, the dataset may not include the original tweets because it is a 1% random sample. Therefore, only the first occurrence of the retweet is being kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8b6c3bb-2b2e-4086-bf4b-947e95796a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032586, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'no_retweet' containing the contents of the column 'text' without any preceding 'RT @mentions:'\n",
    "df_tweets_raw_data['no_retweet'] = df_tweets_raw_data['text'].str.replace(r'\\bRT @\\w+\\s*:|\\brt @\\w+\\s*:', '', regex=True)\n",
    "\n",
    "# Drop duplicate rows except the first occurrence based on 'no_mention'\n",
    "df_tweets_raw_data.drop_duplicates(subset='no_retweet', keep='first', inplace=True)\n",
    "df_tweets_raw_data = df_tweets_raw_data.reset_index(drop=True)\n",
    "df_tweets_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71129d-96b8-48aa-be25-f7ff6f1d58f0",
   "metadata": {},
   "source": [
    "#### Duplicate tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e176ee8-41a6-457a-8df4-9b848e0f86a0",
   "metadata": {},
   "source": [
    "The dataset was build in a way that if a certain tweet had more than one photo, one copy of the tweet was included per unique photo. Since we are concerned with analysing just the text, those duplicates should be removed. Tweets that bear the same 'tweet_url' are duplicates - we are going to keep only the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5a0b5e-d531-4e92-a16c-58d49cae2a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032586, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data.drop_duplicates(subset='tweet_url', keep='first', inplace=True)\n",
    "df_tweets_raw_data = df_tweets_raw_data.reset_index(drop=True)\n",
    "df_tweets_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c21782-713b-46dd-a8cb-c7a4bf590ae7",
   "metadata": {},
   "source": [
    "#### @mentioned tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932b4c1c-d6b8-49f9-b88c-678c4ee4b61c",
   "metadata": {},
   "source": [
    "A few users @mention copies of tweets towards other specific users creating multiple copies of the same tweet - those duplicates should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bee2afc1-5c61-4212-9dc7-001aec574324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3012003, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'no_mention' containing the contents of the column 'text' without any preceding @mentions\n",
    "df_tweets_raw_data['no_mention'] = df_tweets_raw_data['text'].str.replace(r'@\\w+\\s*', '', regex=True)\n",
    "\n",
    "# Drop duplicate rows except the first occurrence based on 'no_mention'\n",
    "df_tweets_raw_data.drop_duplicates(subset='no_mention', keep='first', inplace=True)\n",
    "df_tweets_raw_data = df_tweets_raw_data.reset_index(drop=True)\n",
    "df_tweets_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db3847-c807-4504-9324-b114074300f8",
   "metadata": {},
   "source": [
    "## Sampling the raw data according to filtering expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e818d364-65b5-40a1-aca8-30992032d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the filtering expressions\n",
    "#filter_words = ['venezuelano', 'venezuelana', 'aporofobia', 'crise', 'discrimina√ß√£o', 'estigma', 'xenofobia', 'roraizuela', 'preconceito']\n",
    "filter_words = ['venezuelano', 'venezuelana', 'aporofobia', 'discrimina√ß√£o', 'estigma', 'xenofobia', 'roraizuela']\n",
    "\n",
    "# Creating a boolean mask for filtering\n",
    "mask = df_tweets_raw_data['text'].str.contains('|'.join(filter_words), case=False)\n",
    "\n",
    "# Applying the mask to create 'df_tweets_filtered'\n",
    "df_tweets_filtered = df_tweets_raw_data[mask]\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19db4718-37a5-4895-8f3c-cac12e4aa6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "      <th>no_retweet</th>\n",
       "      <th>no_mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-13 15:01:06</td>\n",
       "      <td>2316329808</td>\n",
       "      <td>SrtaXiss</td>\n",
       "      <td>https://twitter.com/SrtaXiss/status/7865825419...</td>\n",
       "      <td>RT @BR_DeTodos200Mi: Grupo distribui comida pa...</td>\n",
       "      <td>Grupo distribui comida para venezuelanos nas ...</td>\n",
       "      <td>RT : Grupo distribui comida para venezuelanos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-14 14:05:00</td>\n",
       "      <td>19065418</td>\n",
       "      <td>juliosevero</td>\n",
       "      <td>https://twitter.com/juliosevero/status/7869308...</td>\n",
       "      <td>ONU nomeia primeiro investigador de ‚Äúdiscrimin...</td>\n",
       "      <td>ONU nomeia primeiro investigador de ‚Äúdiscrimin...</td>\n",
       "      <td>ONU nomeia primeiro investigador de ‚Äúdiscrimin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-13 12:37:35</td>\n",
       "      <td>4876348647</td>\n",
       "      <td>ins_ana_</td>\n",
       "      <td>https://twitter.com/ins_ana_/status/7865464248...</td>\n",
       "      <td>RT @correio_dopovo: Roraima prepara gabinete d...</td>\n",
       "      <td>Roraima prepara gabinete de emerg√™ncia para c...</td>\n",
       "      <td>RT : Roraima prepara gabinete de emerg√™ncia pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-25 13:00:11</td>\n",
       "      <td>2858025838</td>\n",
       "      <td>ireneravachero3</td>\n",
       "      <td>https://twitter.com/ireneravachero3/status/790...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-13 16:01:26</td>\n",
       "      <td>2538490328</td>\n",
       "      <td>samurai_of_LORD</td>\n",
       "      <td>https://twitter.com/samurai_of_LORD/status/786...</td>\n",
       "      <td>RT @juliosevero: ONU nomeia primeiro investiga...</td>\n",
       "      <td>ONU nomeia primeiro investigador de ‚Äúdiscrimi...</td>\n",
       "      <td>RT : ONU nomeia primeiro investigador de ‚Äúdisc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49491</th>\n",
       "      <td>2022-09-16 21:21:15</td>\n",
       "      <td>1557186008810196992</td>\n",
       "      <td>oliviarf0</td>\n",
       "      <td>https://twitter.com/oliviarf0/status/157088555...</td>\n",
       "      <td>RT @geovana73278250: comeca logo copa p come√ßa...</td>\n",
       "      <td>comeca logo copa p come√ßar a xenofobia logoüòàüòàüòà</td>\n",
       "      <td>RT : comeca logo copa p come√ßar a xenofobia lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49492</th>\n",
       "      <td>2022-09-21 04:22:29</td>\n",
       "      <td>1400181756897148928</td>\n",
       "      <td>LucasStellato10</td>\n",
       "      <td>https://twitter.com/LucasStellato10/status/157...</td>\n",
       "      <td>RT @duartecomenta: Dona deolane fazendo XENOFO...</td>\n",
       "      <td>Dona deolane fazendo XENOFOBIA. Ser√° que v√£o ...</td>\n",
       "      <td>RT : Dona deolane fazendo XENOFOBIA. Ser√° que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49493</th>\n",
       "      <td>2022-09-21 05:27:37</td>\n",
       "      <td>1247249233918545920</td>\n",
       "      <td>HBiancaVs</td>\n",
       "      <td>https://twitter.com/HBiancaVs/status/157245750...</td>\n",
       "      <td>RT @oppscausey: Homofobia ao vivo Xenofobia ac...</td>\n",
       "      <td>Homofobia ao vivo Xenofobia acontecendo  E un...</td>\n",
       "      <td>RT : Homofobia ao vivo Xenofobia acontecendo  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49494</th>\n",
       "      <td>2022-09-21 04:00:12</td>\n",
       "      <td>1182760455988764672</td>\n",
       "      <td>ericacomentx</td>\n",
       "      <td>https://twitter.com/ericacomentx/status/157243...</td>\n",
       "      <td>enfiem esse neg√≥cio de xenofobia no rabo e esp...</td>\n",
       "      <td>enfiem esse neg√≥cio de xenofobia no rabo e esp...</td>\n",
       "      <td>enfiem esse neg√≥cio de xenofobia no rabo e esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49495</th>\n",
       "      <td>2022-09-21 17:23:50</td>\n",
       "      <td>1512530391550279680</td>\n",
       "      <td>Vivianemanaia06</td>\n",
       "      <td>https://twitter.com/Vivianemanaia06/status/157...</td>\n",
       "      <td>@Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...</td>\n",
       "      <td>@Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...</td>\n",
       "      <td>Xenofobia ? Ela √© pernambucano gente...A√≠ tbm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49496 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at            author_id         username  \\\n",
       "0     2016-10-13 15:01:06           2316329808         SrtaXiss   \n",
       "1     2016-10-14 14:05:00             19065418      juliosevero   \n",
       "2     2016-10-13 12:37:35           4876348647         ins_ana_   \n",
       "3     2016-10-25 13:00:11           2858025838  ireneravachero3   \n",
       "4     2016-10-13 16:01:26           2538490328  samurai_of_LORD   \n",
       "...                   ...                  ...              ...   \n",
       "49491 2022-09-16 21:21:15  1557186008810196992        oliviarf0   \n",
       "49492 2022-09-21 04:22:29  1400181756897148928  LucasStellato10   \n",
       "49493 2022-09-21 05:27:37  1247249233918545920        HBiancaVs   \n",
       "49494 2022-09-21 04:00:12  1182760455988764672     ericacomentx   \n",
       "49495 2022-09-21 17:23:50  1512530391550279680  Vivianemanaia06   \n",
       "\n",
       "                                               tweet_url  \\\n",
       "0      https://twitter.com/SrtaXiss/status/7865825419...   \n",
       "1      https://twitter.com/juliosevero/status/7869308...   \n",
       "2      https://twitter.com/ins_ana_/status/7865464248...   \n",
       "3      https://twitter.com/ireneravachero3/status/790...   \n",
       "4      https://twitter.com/samurai_of_LORD/status/786...   \n",
       "...                                                  ...   \n",
       "49491  https://twitter.com/oliviarf0/status/157088555...   \n",
       "49492  https://twitter.com/LucasStellato10/status/157...   \n",
       "49493  https://twitter.com/HBiancaVs/status/157245750...   \n",
       "49494  https://twitter.com/ericacomentx/status/157243...   \n",
       "49495  https://twitter.com/Vivianemanaia06/status/157...   \n",
       "\n",
       "                                                    text  \\\n",
       "0      RT @BR_DeTodos200Mi: Grupo distribui comida pa...   \n",
       "1      ONU nomeia primeiro investigador de ‚Äúdiscrimin...   \n",
       "2      RT @correio_dopovo: Roraima prepara gabinete d...   \n",
       "3      E quanto a situa√ß√£o dos Venezuelanos,silencio ...   \n",
       "4      RT @juliosevero: ONU nomeia primeiro investiga...   \n",
       "...                                                  ...   \n",
       "49491  RT @geovana73278250: comeca logo copa p come√ßa...   \n",
       "49492  RT @duartecomenta: Dona deolane fazendo XENOFO...   \n",
       "49493  RT @oppscausey: Homofobia ao vivo Xenofobia ac...   \n",
       "49494  enfiem esse neg√≥cio de xenofobia no rabo e esp...   \n",
       "49495  @Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...   \n",
       "\n",
       "                                              no_retweet  \\\n",
       "0       Grupo distribui comida para venezuelanos nas ...   \n",
       "1      ONU nomeia primeiro investigador de ‚Äúdiscrimin...   \n",
       "2       Roraima prepara gabinete de emerg√™ncia para c...   \n",
       "3      E quanto a situa√ß√£o dos Venezuelanos,silencio ...   \n",
       "4       ONU nomeia primeiro investigador de ‚Äúdiscrimi...   \n",
       "...                                                  ...   \n",
       "49491     comeca logo copa p come√ßar a xenofobia logoüòàüòàüòà   \n",
       "49492   Dona deolane fazendo XENOFOBIA. Ser√° que v√£o ...   \n",
       "49493   Homofobia ao vivo Xenofobia acontecendo  E un...   \n",
       "49494  enfiem esse neg√≥cio de xenofobia no rabo e esp...   \n",
       "49495  @Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...   \n",
       "\n",
       "                                              no_mention  \n",
       "0      RT : Grupo distribui comida para venezuelanos ...  \n",
       "1      ONU nomeia primeiro investigador de ‚Äúdiscrimin...  \n",
       "2      RT : Roraima prepara gabinete de emerg√™ncia pa...  \n",
       "3      E quanto a situa√ß√£o dos Venezuelanos,silencio ...  \n",
       "4      RT : ONU nomeia primeiro investigador de ‚Äúdisc...  \n",
       "...                                                  ...  \n",
       "49491  RT : comeca logo copa p come√ßar a xenofobia lo...  \n",
       "49492  RT : Dona deolane fazendo XENOFOBIA. Ser√° que ...  \n",
       "49493  RT : Homofobia ao vivo Xenofobia acontecendo  ...  \n",
       "49494  enfiem esse neg√≥cio de xenofobia no rabo e esp...  \n",
       "49495  Xenofobia ? Ela √© pernambucano gente...A√≠ tbm ...  \n",
       "\n",
       "[49496 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128b9f3a-5604-4efa-82a5-780b9b1f7837",
   "metadata": {},
   "source": [
    "### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c99e0e64-6977-47d0-a15a-9ea1abce8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_emojified.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d795b-b60f-4bcc-8a08-6553684308be",
   "metadata": {},
   "source": [
    "The original set of filter words resulted in 496,811 tweets. According to Professor Tony, the recommended number of texts should fall between 20 and 50 thousand tweets. Inspecting the file `tweets_emojified.tsv` as follows, it has been determined that the words 'crise' and 'preconceito' are responsible for the majority of the selected tweets. Therefore, it has been decided to remove them."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3f44665-a8e0-42b4-89de-29914b0cfb97",
   "metadata": {},
   "source": [
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ ll\n",
    "total 1769052\n",
    "drwxrwxrwx 1 eyamrog eyamrog        512 Jul  8 16:44 ./\n",
    "drwxrwxrwx 1 eyamrog eyamrog        512 Jul  8 16:38 ../\n",
    "drwxrwxrwx 1 eyamrog eyamrog        512 Jul  8 16:24 .ipynb_checkpoints/\n",
    "-rwxrwxrwx 1 eyamrog eyamrog      66359 Jul  8 16:44 CL_St1_Mariana.ipynb*\n",
    "-rwxrwxrwx 1 eyamrog eyamrog 1609093422 Jul  8 16:21 mari2016_2022_pt.jsonl*\n",
    "-rwxrwxrwx 1 eyamrog eyamrog  202338605 Jul  8 16:43 tweets_emojified.tsv*\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"venezuelano\" tweets_emojified.tsv\n",
    "14661\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"venezuelana\" tweets_emojified.tsv\n",
    "5327\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"aporofobia\" tweets_emojified.tsv\n",
    "150\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"crise\" tweets_emojified.tsv\n",
    "338401\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"discrimina√ß√£o\" tweets_emojified.tsv\n",
    "7490\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"estigma\" tweets_emojified.tsv\n",
    "6017\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"xenofobia\" tweets_emojified.tsv\n",
    "16018\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"roraizuela\" tweets_emojified.tsv\n",
    "6\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$ grep -ic \"preconceito\" tweets_emojified.tsv\n",
    "110800\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_mariana$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d8c1a-2600-4b18-a1c7-0141fdcd40ea",
   "metadata": {},
   "source": [
    "## Replacing emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478255c-a7a8-48f0-9608-999dc92464a4",
   "metadata": {},
   "source": [
    "### Demojifying the column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2341baec-2fa0-4ee8-82cf-1522257ab02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to demojify a string\n",
    "def demojify_line(input_line):\n",
    "    demojified_line = demoji.replace_with_desc(input_line, sep='<em>')\n",
    "    return demojified_line\n",
    "\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(demojify_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08405272-4072-4cbe-92c0-c221d3848181",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19a2453a-9a6a-4811-ad67-4a7ad495d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_demojified1.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ee493-3e57-4d46-817d-b7a4af0b0722",
   "metadata": {},
   "source": [
    "### Separating the demojified strings with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d55d111-b676-4569-89a0-a1c4ec2e57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to separate the demojified strings with spaces\n",
    "def preprocess_line(input_line):\n",
    "    # Add a space before the first delimiter '<em>', if it is not already preceded by one\n",
    "    preprocessed_line = re.sub(r'(?<! )<em>', ' <em>', input_line)\n",
    "    # Add a space after the first delimiter '<em>', if it is not already followed by one\n",
    "    preprocessed_line = re.sub(r'<em>(?! )', '<em> ', preprocessed_line)\n",
    "    return preprocessed_line\n",
    "\n",
    "# Separating the demojified strings with spaces\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(preprocess_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb282a-30a2-4401-80ac-305aa5f9d7c5",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa3fce08-90f6-4e6a-97f7-ae69517a3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_demojified2.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b2004-f565-44f9-9d43-31bf393170d8",
   "metadata": {},
   "source": [
    "### Formatting the demojified strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2357ac57-bf81-4377-9a21-90fb79d1fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to format the demojified string\n",
    "def format_demojified_string(input_line):\n",
    "    # Defining a function to format the demojified string using RegEx\n",
    "    def process_demojified_string(s):\n",
    "            # Lowercase the string\n",
    "            s = s.lower()\n",
    "            # Replace spaces and colons followed by a space with underscores\n",
    "            s = re.sub(r'(: )| ', '_', s)\n",
    "            # Add the appropriate prefixes and suffixes\n",
    "            s = f'EMOJI{s}e'\n",
    "            return s\n",
    "\n",
    "    # Use RegEx to find and process each demojified string\n",
    "    processed_line = re.sub(r'<em>(.*?)<em>', lambda match: process_demojified_string(match.group(1)), input_line)\n",
    "    return processed_line\n",
    "\n",
    "# Formatting the demojified strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(format_demojified_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743b0db-02a0-4e0b-b0b5-d6659960bc30",
   "metadata": {},
   "source": [
    "### Replacing the `pipe` character by the `-` character in the `text` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc943030-7448-4d4d-98b8-b03c40e113e2",
   "metadata": {},
   "source": [
    "Further on, a few columns of the dataframe are going to be exported into the file `tweets.txt` whose columns need to be delimited by the `pipe` character. Therefore, it is recommended that any occurrences of the `pipe` character in the `text` column are replaced by another character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab1c3584-ae80-41fc-b03a-4286a564a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace the 'pipe' character by the '-' character\n",
    "def replace_pipe_with_hyphen(input_string):\n",
    "    modified_string = re.sub(r'\\|', '-', input_string)\n",
    "    return modified_string\n",
    "\n",
    "# Replacing the 'pipe' character by the '-' character\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(replace_pipe_with_hyphen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d28f3-7d63-4c02-ba55-0dbc957a4291",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aab47cc6-5888-418a-8e4f-97daaf2ac3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_demojified3.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d4ca4-2999-47d3-ae97-b4f3a7599d84",
   "metadata": {},
   "source": [
    "## Tokenising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f950bc7-9ffa-4d96-9ce0-439643f90a55",
   "metadata": {},
   "source": [
    "Please refer to [What is tokenization in NLP?](https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c1d393e-e85d-48f8-93f2-d7dfec6a2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to tokenise a string\n",
    "def tokenise_string(input_line):\n",
    "    # Replace URLs with placeholders\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b'\n",
    "    placeholder = '<URL>'  # Choose a unique placeholder\n",
    "    urls = re.findall(url_pattern, input_line)\n",
    "    tokenised_line = re.sub(url_pattern, placeholder, input_line)  # Replace URLs with placeholders\n",
    "    \n",
    "    # Replace curly quotes with straight ones\n",
    "    tokenised_line = tokenised_line.replace('‚Äú', '\"').replace('‚Äù', '\"').replace(\"‚Äò\", \"'\").replace(\"‚Äô\", \"'\")\n",
    "    # Separate common punctuation marks with spaces\n",
    "    tokenised_line = re.sub(r'([.\\!?,\"\\'/()])', r' \\1 ', tokenised_line)\n",
    "    # Add a space before '#'\n",
    "    tokenised_line = re.sub(r'(?<!\\s)#', r' #', tokenised_line)  # Add a space before '#' if it is not already preceded by one\n",
    "    # Reduce extra spaces by a single space\n",
    "    tokenised_line = re.sub(r'\\s+', ' ', tokenised_line)\n",
    "    \n",
    "    # Replace the placeholders with the respective URLs\n",
    "    for url in urls:\n",
    "        tokenised_line = tokenised_line.replace(placeholder, url, 1)\n",
    "    \n",
    "    return tokenised_line\n",
    "\n",
    "# Tokenising the strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(tokenise_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad8cc4-bd36-4d7a-905e-55173081cd85",
   "metadata": {},
   "source": [
    "## Creating the files `file_index.txt` and `tweets.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a908ea-85cd-4ded-b752-2ce8ccee6f62",
   "metadata": {},
   "source": [
    "### Creating column `text_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e69b8a02-8d66-4227-838a-020f8e458225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_id'] = 't' + df_tweets_filtered.index.astype(str).str.zfill(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ecbc7-802a-4546-b770-bd94372e58f7",
   "metadata": {},
   "source": [
    "### Creating column `conversation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b26c71e4-6d0a-4f1f-a343-412755ec2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['author_id'] = df_tweets_filtered['author_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ad070c7-3caf-4eb8-8dfe-eba469fe0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['conversation'] = 'v:' + df_tweets_filtered['author_id'].str.replace('id_', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85be5b3-f3ec-4061-a9c7-6d29591a8efd",
   "metadata": {},
   "source": [
    "### Creating column `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc30acc9-8d7d-41ef-9e33-2367d4c1462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'created_at' to datetime format\n",
    "df_tweets_filtered['created_at'] = pd.to_datetime(df_tweets_filtered['created_at'])\n",
    "\n",
    "# Extract the date part (without time) into a new column 'date'\n",
    "df_tweets_filtered['date'] = df_tweets_filtered['created_at'].dt.date\n",
    "\n",
    "# Add the prefix 'd:' to the 'date' values\n",
    "df_tweets_filtered['date'] = 'd:' + df_tweets_filtered['date'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067eec7-aedb-4bba-8241-5d5d000f6226",
   "metadata": {},
   "source": [
    "### Creating column `text_url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a5dec9e-0791-4b40-b59e-b46b62d400ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_url'] = 'url:' + df_tweets_filtered['tweet_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c35b3-69bc-4039-aa13-6b496f81c729",
   "metadata": {},
   "source": [
    "### Creating column `user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5700d8af-3be8-4a60-bd3d-1ddf3df356ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['user'] = 'u:' + df_tweets_filtered['username']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d2a83-b1a0-4db7-b9d3-e6d91202402c",
   "metadata": {},
   "source": [
    "### Creating column `content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd9313bd-6cbe-487c-a152-de678559260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['content'] = 'c:' + df_tweets_filtered['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11872fa-2b44-4302-ab43-f98f64692eaf",
   "metadata": {},
   "source": [
    "### Reordering the created columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538070e-1838-454f-a761-549e2bd5bc36",
   "metadata": {},
   "source": [
    "Please refer to:\n",
    "- [Python - List Comprehension 1](https://www.w3schools.com/python/python_lists_comprehension.asp)\n",
    "- [Python - List Comprehension 2](https://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afc325f4-43c7-4ba8-b10f-130974d8c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns (we use list comprehension to create a list of all columns except 'text_id', 'variable', 'date' and 'text_url')\n",
    "df_tweets_filtered = df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url', 'user', 'content'] + [col for col in df_tweets_filtered.columns if col not in ['text_id', 'conversation', 'date', 'text_url', 'user', 'content']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1217907f-187c-4d64-a97a-e7a9c607f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>conversation</th>\n",
       "      <th>date</th>\n",
       "      <th>text_url</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "      <th>no_retweet</th>\n",
       "      <th>no_mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t000000</td>\n",
       "      <td>v:2316329808</td>\n",
       "      <td>d:2016-10-13</td>\n",
       "      <td>url:https://twitter.com/SrtaXiss/status/786582...</td>\n",
       "      <td>u:SrtaXiss</td>\n",
       "      <td>c:RT @BR_DeTodos200Mi: Grupo distribui comida ...</td>\n",
       "      <td>2016-10-13 15:01:06</td>\n",
       "      <td>2316329808</td>\n",
       "      <td>SrtaXiss</td>\n",
       "      <td>https://twitter.com/SrtaXiss/status/7865825419...</td>\n",
       "      <td>RT @BR_DeTodos200Mi: Grupo distribui comida pa...</td>\n",
       "      <td>Grupo distribui comida para venezuelanos nas ...</td>\n",
       "      <td>RT : Grupo distribui comida para venezuelanos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t000001</td>\n",
       "      <td>v:19065418</td>\n",
       "      <td>d:2016-10-14</td>\n",
       "      <td>url:https://twitter.com/juliosevero/status/786...</td>\n",
       "      <td>u:juliosevero</td>\n",
       "      <td>c:ONU nomeia primeiro investigador de \" discri...</td>\n",
       "      <td>2016-10-14 14:05:00</td>\n",
       "      <td>19065418</td>\n",
       "      <td>juliosevero</td>\n",
       "      <td>https://twitter.com/juliosevero/status/7869308...</td>\n",
       "      <td>ONU nomeia primeiro investigador de \" discrimi...</td>\n",
       "      <td>ONU nomeia primeiro investigador de ‚Äúdiscrimin...</td>\n",
       "      <td>ONU nomeia primeiro investigador de ‚Äúdiscrimin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t000002</td>\n",
       "      <td>v:4876348647</td>\n",
       "      <td>d:2016-10-13</td>\n",
       "      <td>url:https://twitter.com/ins_ana_/status/786546...</td>\n",
       "      <td>u:ins_ana_</td>\n",
       "      <td>c:RT @correio_dopovo: Roraima prepara gabinete...</td>\n",
       "      <td>2016-10-13 12:37:35</td>\n",
       "      <td>4876348647</td>\n",
       "      <td>ins_ana_</td>\n",
       "      <td>https://twitter.com/ins_ana_/status/7865464248...</td>\n",
       "      <td>RT @correio_dopovo: Roraima prepara gabinete d...</td>\n",
       "      <td>Roraima prepara gabinete de emerg√™ncia para c...</td>\n",
       "      <td>RT : Roraima prepara gabinete de emerg√™ncia pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t000003</td>\n",
       "      <td>v:2858025838</td>\n",
       "      <td>d:2016-10-25</td>\n",
       "      <td>url:https://twitter.com/ireneravachero3/status...</td>\n",
       "      <td>u:ireneravachero3</td>\n",
       "      <td>c:E quanto a situa√ß√£o dos Venezuelanos , silen...</td>\n",
       "      <td>2016-10-25 13:00:11</td>\n",
       "      <td>2858025838</td>\n",
       "      <td>ireneravachero3</td>\n",
       "      <td>https://twitter.com/ireneravachero3/status/790...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos , silenci...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t000004</td>\n",
       "      <td>v:2538490328</td>\n",
       "      <td>d:2016-10-13</td>\n",
       "      <td>url:https://twitter.com/samurai_of_LORD/status...</td>\n",
       "      <td>u:samurai_of_LORD</td>\n",
       "      <td>c:RT @juliosevero: ONU nomeia primeiro investi...</td>\n",
       "      <td>2016-10-13 16:01:26</td>\n",
       "      <td>2538490328</td>\n",
       "      <td>samurai_of_LORD</td>\n",
       "      <td>https://twitter.com/samurai_of_LORD/status/786...</td>\n",
       "      <td>RT @juliosevero: ONU nomeia primeiro investiga...</td>\n",
       "      <td>ONU nomeia primeiro investigador de ‚Äúdiscrimi...</td>\n",
       "      <td>RT : ONU nomeia primeiro investigador de ‚Äúdisc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49491</th>\n",
       "      <td>t049491</td>\n",
       "      <td>v:1557186008810196992</td>\n",
       "      <td>d:2022-09-16</td>\n",
       "      <td>url:https://twitter.com/oliviarf0/status/15708...</td>\n",
       "      <td>u:oliviarf0</td>\n",
       "      <td>c:RT @geovana73278250: comeca logo copa p come...</td>\n",
       "      <td>2022-09-16 21:21:15</td>\n",
       "      <td>1557186008810196992</td>\n",
       "      <td>oliviarf0</td>\n",
       "      <td>https://twitter.com/oliviarf0/status/157088555...</td>\n",
       "      <td>RT @geovana73278250: comeca logo copa p come√ßa...</td>\n",
       "      <td>comeca logo copa p come√ßar a xenofobia logoüòàüòàüòà</td>\n",
       "      <td>RT : comeca logo copa p come√ßar a xenofobia lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49492</th>\n",
       "      <td>t049492</td>\n",
       "      <td>v:1400181756897148928</td>\n",
       "      <td>d:2022-09-21</td>\n",
       "      <td>url:https://twitter.com/LucasStellato10/status...</td>\n",
       "      <td>u:LucasStellato10</td>\n",
       "      <td>c:RT @duartecomenta: Dona deolane fazendo XENO...</td>\n",
       "      <td>2022-09-21 04:22:29</td>\n",
       "      <td>1400181756897148928</td>\n",
       "      <td>LucasStellato10</td>\n",
       "      <td>https://twitter.com/LucasStellato10/status/157...</td>\n",
       "      <td>RT @duartecomenta: Dona deolane fazendo XENOFO...</td>\n",
       "      <td>Dona deolane fazendo XENOFOBIA. Ser√° que v√£o ...</td>\n",
       "      <td>RT : Dona deolane fazendo XENOFOBIA. Ser√° que ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49493</th>\n",
       "      <td>t049493</td>\n",
       "      <td>v:1247249233918545920</td>\n",
       "      <td>d:2022-09-21</td>\n",
       "      <td>url:https://twitter.com/HBiancaVs/status/15724...</td>\n",
       "      <td>u:HBiancaVs</td>\n",
       "      <td>c:RT @oppscausey: Homofobia ao vivo Xenofobia ...</td>\n",
       "      <td>2022-09-21 05:27:37</td>\n",
       "      <td>1247249233918545920</td>\n",
       "      <td>HBiancaVs</td>\n",
       "      <td>https://twitter.com/HBiancaVs/status/157245750...</td>\n",
       "      <td>RT @oppscausey: Homofobia ao vivo Xenofobia ac...</td>\n",
       "      <td>Homofobia ao vivo Xenofobia acontecendo  E un...</td>\n",
       "      <td>RT : Homofobia ao vivo Xenofobia acontecendo  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49494</th>\n",
       "      <td>t049494</td>\n",
       "      <td>v:1182760455988764672</td>\n",
       "      <td>d:2022-09-21</td>\n",
       "      <td>url:https://twitter.com/ericacomentx/status/15...</td>\n",
       "      <td>u:ericacomentx</td>\n",
       "      <td>c:enfiem esse neg√≥cio de xenofobia no rabo e e...</td>\n",
       "      <td>2022-09-21 04:00:12</td>\n",
       "      <td>1182760455988764672</td>\n",
       "      <td>ericacomentx</td>\n",
       "      <td>https://twitter.com/ericacomentx/status/157243...</td>\n",
       "      <td>enfiem esse neg√≥cio de xenofobia no rabo e esp...</td>\n",
       "      <td>enfiem esse neg√≥cio de xenofobia no rabo e esp...</td>\n",
       "      <td>enfiem esse neg√≥cio de xenofobia no rabo e esp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49495</th>\n",
       "      <td>t049495</td>\n",
       "      <td>v:1512530391550279680</td>\n",
       "      <td>d:2022-09-21</td>\n",
       "      <td>url:https://twitter.com/Vivianemanaia06/status...</td>\n",
       "      <td>u:Vivianemanaia06</td>\n",
       "      <td>c:@Lucas_Bertoldo Xenofobia ? Ela √© pernambuca...</td>\n",
       "      <td>2022-09-21 17:23:50</td>\n",
       "      <td>1512530391550279680</td>\n",
       "      <td>Vivianemanaia06</td>\n",
       "      <td>https://twitter.com/Vivianemanaia06/status/157...</td>\n",
       "      <td>@Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...</td>\n",
       "      <td>@Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...</td>\n",
       "      <td>Xenofobia ? Ela √© pernambucano gente...A√≠ tbm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49496 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_id           conversation          date  \\\n",
       "0      t000000           v:2316329808  d:2016-10-13   \n",
       "1      t000001             v:19065418  d:2016-10-14   \n",
       "2      t000002           v:4876348647  d:2016-10-13   \n",
       "3      t000003           v:2858025838  d:2016-10-25   \n",
       "4      t000004           v:2538490328  d:2016-10-13   \n",
       "...        ...                    ...           ...   \n",
       "49491  t049491  v:1557186008810196992  d:2022-09-16   \n",
       "49492  t049492  v:1400181756897148928  d:2022-09-21   \n",
       "49493  t049493  v:1247249233918545920  d:2022-09-21   \n",
       "49494  t049494  v:1182760455988764672  d:2022-09-21   \n",
       "49495  t049495  v:1512530391550279680  d:2022-09-21   \n",
       "\n",
       "                                                text_url               user  \\\n",
       "0      url:https://twitter.com/SrtaXiss/status/786582...         u:SrtaXiss   \n",
       "1      url:https://twitter.com/juliosevero/status/786...      u:juliosevero   \n",
       "2      url:https://twitter.com/ins_ana_/status/786546...         u:ins_ana_   \n",
       "3      url:https://twitter.com/ireneravachero3/status...  u:ireneravachero3   \n",
       "4      url:https://twitter.com/samurai_of_LORD/status...  u:samurai_of_LORD   \n",
       "...                                                  ...                ...   \n",
       "49491  url:https://twitter.com/oliviarf0/status/15708...        u:oliviarf0   \n",
       "49492  url:https://twitter.com/LucasStellato10/status...  u:LucasStellato10   \n",
       "49493  url:https://twitter.com/HBiancaVs/status/15724...        u:HBiancaVs   \n",
       "49494  url:https://twitter.com/ericacomentx/status/15...     u:ericacomentx   \n",
       "49495  url:https://twitter.com/Vivianemanaia06/status...  u:Vivianemanaia06   \n",
       "\n",
       "                                                 content          created_at  \\\n",
       "0      c:RT @BR_DeTodos200Mi: Grupo distribui comida ... 2016-10-13 15:01:06   \n",
       "1      c:ONU nomeia primeiro investigador de \" discri... 2016-10-14 14:05:00   \n",
       "2      c:RT @correio_dopovo: Roraima prepara gabinete... 2016-10-13 12:37:35   \n",
       "3      c:E quanto a situa√ß√£o dos Venezuelanos , silen... 2016-10-25 13:00:11   \n",
       "4      c:RT @juliosevero: ONU nomeia primeiro investi... 2016-10-13 16:01:26   \n",
       "...                                                  ...                 ...   \n",
       "49491  c:RT @geovana73278250: comeca logo copa p come... 2022-09-16 21:21:15   \n",
       "49492  c:RT @duartecomenta: Dona deolane fazendo XENO... 2022-09-21 04:22:29   \n",
       "49493  c:RT @oppscausey: Homofobia ao vivo Xenofobia ... 2022-09-21 05:27:37   \n",
       "49494  c:enfiem esse neg√≥cio de xenofobia no rabo e e... 2022-09-21 04:00:12   \n",
       "49495  c:@Lucas_Bertoldo Xenofobia ? Ela √© pernambuca... 2022-09-21 17:23:50   \n",
       "\n",
       "                 author_id         username  \\\n",
       "0               2316329808         SrtaXiss   \n",
       "1                 19065418      juliosevero   \n",
       "2               4876348647         ins_ana_   \n",
       "3               2858025838  ireneravachero3   \n",
       "4               2538490328  samurai_of_LORD   \n",
       "...                    ...              ...   \n",
       "49491  1557186008810196992        oliviarf0   \n",
       "49492  1400181756897148928  LucasStellato10   \n",
       "49493  1247249233918545920        HBiancaVs   \n",
       "49494  1182760455988764672     ericacomentx   \n",
       "49495  1512530391550279680  Vivianemanaia06   \n",
       "\n",
       "                                               tweet_url  \\\n",
       "0      https://twitter.com/SrtaXiss/status/7865825419...   \n",
       "1      https://twitter.com/juliosevero/status/7869308...   \n",
       "2      https://twitter.com/ins_ana_/status/7865464248...   \n",
       "3      https://twitter.com/ireneravachero3/status/790...   \n",
       "4      https://twitter.com/samurai_of_LORD/status/786...   \n",
       "...                                                  ...   \n",
       "49491  https://twitter.com/oliviarf0/status/157088555...   \n",
       "49492  https://twitter.com/LucasStellato10/status/157...   \n",
       "49493  https://twitter.com/HBiancaVs/status/157245750...   \n",
       "49494  https://twitter.com/ericacomentx/status/157243...   \n",
       "49495  https://twitter.com/Vivianemanaia06/status/157...   \n",
       "\n",
       "                                                    text  \\\n",
       "0      RT @BR_DeTodos200Mi: Grupo distribui comida pa...   \n",
       "1      ONU nomeia primeiro investigador de \" discrimi...   \n",
       "2      RT @correio_dopovo: Roraima prepara gabinete d...   \n",
       "3      E quanto a situa√ß√£o dos Venezuelanos , silenci...   \n",
       "4      RT @juliosevero: ONU nomeia primeiro investiga...   \n",
       "...                                                  ...   \n",
       "49491  RT @geovana73278250: comeca logo copa p come√ßa...   \n",
       "49492  RT @duartecomenta: Dona deolane fazendo XENOFO...   \n",
       "49493  RT @oppscausey: Homofobia ao vivo Xenofobia ac...   \n",
       "49494  enfiem esse neg√≥cio de xenofobia no rabo e esp...   \n",
       "49495  @Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...   \n",
       "\n",
       "                                              no_retweet  \\\n",
       "0       Grupo distribui comida para venezuelanos nas ...   \n",
       "1      ONU nomeia primeiro investigador de ‚Äúdiscrimin...   \n",
       "2       Roraima prepara gabinete de emerg√™ncia para c...   \n",
       "3      E quanto a situa√ß√£o dos Venezuelanos,silencio ...   \n",
       "4       ONU nomeia primeiro investigador de ‚Äúdiscrimi...   \n",
       "...                                                  ...   \n",
       "49491     comeca logo copa p come√ßar a xenofobia logoüòàüòàüòà   \n",
       "49492   Dona deolane fazendo XENOFOBIA. Ser√° que v√£o ...   \n",
       "49493   Homofobia ao vivo Xenofobia acontecendo  E un...   \n",
       "49494  enfiem esse neg√≥cio de xenofobia no rabo e esp...   \n",
       "49495  @Lucas_Bertoldo Xenofobia ? Ela √© pernambucano...   \n",
       "\n",
       "                                              no_mention  \n",
       "0      RT : Grupo distribui comida para venezuelanos ...  \n",
       "1      ONU nomeia primeiro investigador de ‚Äúdiscrimin...  \n",
       "2      RT : Roraima prepara gabinete de emerg√™ncia pa...  \n",
       "3      E quanto a situa√ß√£o dos Venezuelanos,silencio ...  \n",
       "4      RT : ONU nomeia primeiro investigador de ‚Äúdisc...  \n",
       "...                                                  ...  \n",
       "49491  RT : comeca logo copa p come√ßar a xenofobia lo...  \n",
       "49492  RT : Dona deolane fazendo XENOFOBIA. Ser√° que ...  \n",
       "49493  RT : Homofobia ao vivo Xenofobia acontecendo  ...  \n",
       "49494  enfiem esse neg√≥cio de xenofobia no rabo e esp...  \n",
       "49495  Xenofobia ? Ela √© pernambucano gente...A√≠ tbm ...  \n",
       "\n",
       "[49496 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f23e3-bc12-4150-8bf1-557184b40d1b",
   "metadata": {},
   "source": [
    "### Creating the file `file_index.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "199bbbe5-a366-4fde-9314-f0de3d49c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url']].to_csv('file_index.txt', sep=' ', index=False, header=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd415c21-39dc-4083-9632-e5cd92fa6948",
   "metadata": {},
   "source": [
    "### Creating the file `tweets.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5445fc96-0b9f-4283-80b3-09b1bddeab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder tweets already exists\n"
     ]
    }
   ],
   "source": [
    "folder = 'tweets'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "    print(f'Folder {folder} created!')\n",
    "except FileExistsError:\n",
    "    print(f'Folder {folder} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de49e26-5efe-472f-9952-cef41fcda082",
   "metadata": {},
   "source": [
    "Note: The parameters `doublequote=False` and `escapechar=' '` are required to avoid that the column content is doublequoted with '\"' in sentences that use characters that need to be escaped such as double quote '\"' itself - this causes a malformed response from TreeTagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b566e03-56e4-44a8-8558-b6e940bb6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'user', 'content']].to_csv(f'{folder}/tweets.txt', sep='|', index=False, header=False, encoding='utf-8', lineterminator='\\n', doublequote=False, escapechar=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f769843-4ff9-4436-a2e0-d61e2c391e9d",
   "metadata": {},
   "source": [
    "## Tagging with TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3877be9-6317-42ee-8e8d-c15c48f77996",
   "metadata": {},
   "source": [
    "- On Visual Studio Code (VS Code), open the folder where your project is located with `Open Folder...`\n",
    "- Open a WSL Ubuntu Terminal on VS Code\n",
    "- **Important**: Activate the `my_env` Python environment by executing `source \"$HOME\"/my_env/bin/activate`\n",
    "- Proceed as indicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720724ab-5e77-4e9e-b05a-24cf73259cd0",
   "metadata": {},
   "source": [
    "Purpose: Annotate the texts in `tweets/tweets.txt` with part-of-speech and lemma information.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `tweets/tweets.txt`\n",
    "- Output\n",
    "    - `tweets/tagged.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005cc09-f5ef-454f-9b74-4d7ca9fe4f10",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash treetagging.sh\n",
    "--- treetagging t000000 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000001 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000002 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000003 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "<omitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0060ba-d01c-4e48-a353-8c9ba0fc456e",
   "metadata": {},
   "source": [
    "## Processing `tokenstypes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93351bf2-3457-4b47-8a47-7ff13c4e0e1a",
   "metadata": {},
   "source": [
    "Purpose: Capture the content tokens (specific occurrences of words) and the content types (general concept of words) from `tweets/tagged.txt`.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `tweets/tagged.txt`\n",
    "- Output\n",
    "    - `tweets/tokens.txt`\n",
    "    - `tweets/types.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddc717-8ff2-4f38-ae10-8d6616de6a6c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash tokenstypes.sh\n",
    "--- tokenstypes t000000 / 18206 ---\n",
    "--- tokenstypes t000001 / 18206 ---\n",
    "--- tokenstypes t000002 / 18206 ---\n",
    "--- tokenstypes t000003 / 18206 ---\n",
    "--- tokenstypes t000004 / 18206 ---\n",
    "--- tokenstypes t000005 / 18206 ---\n",
    "<omitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef598329-fb5a-4b07-8799-b2bbb55847f1",
   "metadata": {},
   "source": [
    "## Processing `toplemmas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce5796-0434-44d5-88e2-8f934a6cebc8",
   "metadata": {},
   "source": [
    "Purpose: Determine the 1.000 top lemmas. **Important**: This process requires manual inspection. Non-meaningful lemmas should be excluded by updating `stoplist.sed` and reiterating the processing. Proceed as indicated in this [video tutorial](https://youtu.be/4UIPpdoozP0?si=_3md9w79njZY86PE), from 20:05 to 25:16.\n",
    "- Input\n",
    "    - `tweets/types.txt`\n",
    "    - `stoplist.sed`: List of rules that allows the exclusion of a certain lemmas\n",
    "- Output\n",
    "    - `selectedwords` = `var_index.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0fc8e-73e2-4e2d-9e2f-73068e4132fc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash toplemmas.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a4675-5067-4e8b-8ca8-baf9f1b915c1",
   "metadata": {},
   "source": [
    "## Processing `sas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d158b2-73d7-477e-a7a7-2b87216a19ae",
   "metadata": {},
   "source": [
    "Purpose: Prepare input data for processing in SAS.\n",
    "- Input\n",
    "    - `tweets/types.txt`\n",
    "    - `selectedwords`\n",
    "    - `file_index.txt`\n",
    "- Output\n",
    "    - `columns`\n",
    "    - `sas/data.txt`\n",
    "    - `sas/dates.txt`\n",
    "    - `sas/wcount.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d250d29-861c-41a6-9793-e0df758100e0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash sas.sh\n",
    "--- v000001 ---\n",
    "--- v000002 ---\n",
    "--- v000003 ---\n",
    "--- v000004 ---\n",
    "--- v000005 ---\n",
    "<omitted>\n",
    "--- v001000 ---\n",
    "[nltk_data] Downloading package punkt to /home/eyamrog/nltk_data...\n",
    "[nltk_data]   Package punkt is already up-to-date!\n",
    "Word counts written to sas/wcount.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8087ea-ffd4-43b9-8eda-4444b931c319",
   "metadata": {},
   "source": [
    "## Processing `datamatrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4374f48-04b6-48af-a31d-125ef0e85972",
   "metadata": {},
   "source": [
    "Purpose: Prepares input data for calculating the correlation matrix.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `columns`\n",
    "    - `selectedwords`\n",
    "- Output\n",
    "    - `file_ids.txt`\n",
    "    - `data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23925f09-05ef-44a5-ba48-78cac1dedc76",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash datamatrix.sh\n",
    "--- v000001 ---\n",
    "--- v000002 ---\n",
    "--- v000003 ---\n",
    "--- v000004 ---\n",
    "--- v000005 ---\n",
    "<omitted>\n",
    "--- v001000 ---\n",
    "--- data.csv ...---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130e8f0-a7e5-4f6e-b427-090f7cda4856",
   "metadata": {},
   "source": [
    "## Processing `correlationmatrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddbb87-b4de-4c41-8177-b2f677d803b6",
   "metadata": {},
   "source": [
    "Purpose: Calculates the correlation matrix.\n",
    "- Input\n",
    "    - `data.csv`\n",
    "- Output\n",
    "    - `correlation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42927846-5d87-4f5f-8ce6-8beb4ef733a4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash correlationmatrix.sh\n",
    "--- python correlation ... ---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9203f-e9e1-4a73-8bed-7dec1ad8617e",
   "metadata": {},
   "source": [
    "## Processing `formats`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69517100-c28d-44ba-90a7-37988e3df8ad",
   "metadata": {},
   "source": [
    "Purpose: Prepare input data for processing in SAS.\n",
    "- Input\n",
    "    - `data.csv`\n",
    "    - `selectedwords`\n",
    "- Output\n",
    "    - `sas/corr.txt`\n",
    "    - `sas/word_labels_format.sas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9b02f-fd33-4ff2-bf57-463fac9743e6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash formats.sh\n",
    "--- sas/sas/corr.txt ---\n",
    "--- sas/word_labels_format.sas ---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb5b2a-e203-4b3e-80a9-86b10fc0253c",
   "metadata": {},
   "source": [
    "## Processing the statistical procedures on SAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc9cd8-cd80-41d2-8209-f0a363fd9ab2",
   "metadata": {},
   "source": [
    "- Log in to your [SAS OnDemand for Academics](https://welcome.oda.sas.com/) account\n",
    "- Proceed as indicated in this [video tutorial](https://youtu.be/I3u9zD3jyOA?si=68uIKVc2iusGG2KY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed501c0-f6b1-4050-a4eb-a486bb73c036",
   "metadata": {},
   "source": [
    "## Processing `examples`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cef7d2-d981-4d52-b340-3c55ffe0699a",
   "metadata": {},
   "source": [
    "Purpose: Extract examples for analysis.\n",
    "- Input\n",
    "    - `sas/output_\"$project\"/loadtable.html`\n",
    "    - `sas/output_\"$project\"/\"$project\"_scores.tsv`\n",
    "    - `sas/output_\"$project\"/\"$project\"_scores_only.tsv`\n",
    "- Output\n",
    "    - `examples/factors`\n",
    "    - `example files`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf820c-016d-4940-940c-82a587f2c22b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash examples.sh\n",
    "6780\n",
    "1246\n",
    "698\n",
    "123\n",
    "--- examples f1pos ---\n",
    "--- factor 1 pos # 000001 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000002 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000003 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000004 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000005 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "<ommitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38617b-0487-4ba2-b619-d9b78aba9f2c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf501e4a-1193-4999-bdc0-88c08d2840f7",
   "metadata": {},
   "source": [
    "Right-click on the link and choose `Save link as` to download the corresponding file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73ba45-9d6c-4578-b14e-c80c3ccaafe4",
   "metadata": {},
   "source": [
    "- [CL_St1_Mariana_Results.tar.gz](https://pucsp-my.sharepoint.com/:u:/g/personal/ra00341729_pucsp_edu_br/EU1-gvN-4pRDqIuGkPWHry4B6dJ7dY6gWqaKcydFL7evvA?e=AGpfTJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5b60f-6f20-4c7a-ac16-7d0c04c86126",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Proceed as follows to extract the files from the archive `CL_St1_Mariana_Results.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4de1b-c441-4d75-b3f4-deaf61a63192",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ tar xzvf CL_St1_Mariana_Results.tar.gz\n",
    "<omitted>\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb169464-4f29-4513-b272-46f201deff17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
