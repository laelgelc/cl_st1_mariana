{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 1 - Mariana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ad8a7-2d34-476b-be69-5d896b27d3ed",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1209cf-0515-45b3-8856-275ac692943e",
   "metadata": {},
   "source": [
    "Make sure the prerequisites in [CL_LMDA_prerequisites](https://github.com/laelgelc/laelgelc/blob/main/CL_LMDA_prerequisites.ipynb) are satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28897518-a858-4dc5-b510-49c9131da966",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f58941-1578-42c0-8933-d8ebef369245",
   "metadata": {},
   "source": [
    "Please download the following dataset (Right-click on the link and choose `Open link in a new tab` to download the corresponding file):\n",
    "- [mari2016_2022_pt.jsonl](https://pucsp-my.sharepoint.com/:u:/g/personal/ra00341729_pucsp_edu_br/EfSI2XLs9AlKqSkqJUW8TNIBEd_gXpNgxQX7qb7XI7T8Mw?e=iMGZTD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c2af7-9fc1-4f51-a4f5-2ed915b93039",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6689499-d19d-4b0c-befd-f88926b7105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import demoji\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a79a002-c182-4021-9b77-99ad470582af",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e37aae-8cee-42ca-91ff-10f882fc45c6",
   "metadata": {},
   "source": [
    "### Importing the tweet raw data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a762708-07e4-472d-b3e9-bb0cea14438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_raw_data = pd.read_json('mari2016_2022_pt.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623ddacd-5a20-4d89-a48e-98849a0644e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-03 15:00:41</td>\n",
       "      <td>1090552219</td>\n",
       "      <td>PopSeriesBrasil</td>\n",
       "      <td>https://twitter.com/PopSeriesBrasil/status/782...</td>\n",
       "      <td>Sheldon com problemas no novo epis√≥dio de #TBB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-03 15:00:54</td>\n",
       "      <td>2955241713</td>\n",
       "      <td>crl_jana</td>\n",
       "      <td>https://twitter.com/crl_jana/status/7829586130...</td>\n",
       "      <td>\"Pra vcs, qual a causa de viol√™ncia?\" \"inveja ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-30 15:00:02</td>\n",
       "      <td>324548290</td>\n",
       "      <td>pxthifraga_</td>\n",
       "      <td>https://twitter.com/pxthifraga_/status/7927428...</td>\n",
       "      <td>Fui votar e esqueci a identidade,j√° tava no me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-13 15:20:17</td>\n",
       "      <td>2751208197</td>\n",
       "      <td>heeyvasques</td>\n",
       "      <td>https://twitter.com/heeyvasques/status/7865873...</td>\n",
       "      <td>pare√ßo at√© stalker da isabella mas n√£o sou nao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-13 15:20:25</td>\n",
       "      <td>4158067325</td>\n",
       "      <td>Fuckinshadyy</td>\n",
       "      <td>https://twitter.com/Fuckinshadyy/status/786587...</td>\n",
       "      <td>oi crian√ßas, voc√™s gostam de viol√™ncia?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at   author_id         username  \\\n",
       "0 2016-10-03 15:00:41  1090552219  PopSeriesBrasil   \n",
       "1 2016-10-03 15:00:54  2955241713         crl_jana   \n",
       "2 2016-10-30 15:00:02   324548290      pxthifraga_   \n",
       "3 2016-10-13 15:20:17  2751208197      heeyvasques   \n",
       "4 2016-10-13 15:20:25  4158067325     Fuckinshadyy   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0  https://twitter.com/PopSeriesBrasil/status/782...   \n",
       "1  https://twitter.com/crl_jana/status/7829586130...   \n",
       "2  https://twitter.com/pxthifraga_/status/7927428...   \n",
       "3  https://twitter.com/heeyvasques/status/7865873...   \n",
       "4  https://twitter.com/Fuckinshadyy/status/786587...   \n",
       "\n",
       "                                                text  \n",
       "0  Sheldon com problemas no novo epis√≥dio de #TBB...  \n",
       "1  \"Pra vcs, qual a causa de viol√™ncia?\" \"inveja ...  \n",
       "2  Fui votar e esqueci a identidade,j√° tava no me...  \n",
       "3  pare√ßo at√© stalker da isabella mas n√£o sou nao...  \n",
       "4            oi crian√ßas, voc√™s gostam de viol√™ncia?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e11cf2-cb39-49ee-a601-58a4ec3caa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5409904, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bd2975-f291-4fdb-9c2f-51dd6b8c269d",
   "metadata": {},
   "source": [
    "#### Inspecting a few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6109d2f2-4cd1-43ce-86fe-7fb7f1ff8910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username:crl_jana\n",
      "text:\"Pra vcs, qual a causa de viol√™ncia?\" \"inveja professor\" üòÇüòÇüòÇ\n",
      "tweet_url:https://twitter.com/crl_jana/status/782958613010800640\n"
     ]
    }
   ],
   "source": [
    "inspected_row = 1\n",
    "print('username:' + df_tweets_raw_data.loc[inspected_row, 'username'])\n",
    "print('text:' + df_tweets_raw_data.loc[inspected_row, 'text'])\n",
    "print('tweet_url:' + df_tweets_raw_data.loc[inspected_row, 'tweet_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277d732-f65b-4e0c-868d-16d2d38ef04b",
   "metadata": {},
   "source": [
    "### Inspecting the dataset and eliminating malformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a369a-af13-45f0-99b2-6ce5b6388a1c",
   "metadata": {},
   "source": [
    "#### Checking if data types are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6795c314-cc1f-4acd-86a1-a4eada8a9bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at    datetime64[ns]\n",
       "author_id              int64\n",
       "username              object\n",
       "tweet_url             object\n",
       "text                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30643060-8eaa-47e0-9a52-95f6fbd75515",
   "metadata": {},
   "source": [
    "#### Identifying rows that are empty in column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6de7bb2-56d3-41cb-9294-d19dbeca836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_tweets_raw_data['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9e9cf4-0f39-4cdc-84f0-84d8446eea53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_at, author_id, username, tweet_url, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_raw_data[df_tweets_raw_data['text'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc61e-77c5-4339-99ed-e8aea3a1ec42",
   "metadata": {},
   "source": [
    "#### Dropping the rows that are empty in the column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db62e8de-5e85-4474-9bf4-4c9342c2640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows whose column 'text' is NaN\n",
    "df_tweets_raw_data = df_tweets_raw_data.dropna(subset=['text'])\n",
    "\n",
    "# Reset the index\n",
    "df_tweets_raw_data = df_tweets_raw_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44d9a76-464b-41ca-842a-921beae1c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_tweets_raw_data['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db3847-c807-4504-9324-b114074300f8",
   "metadata": {},
   "source": [
    "## Sampling the raw data according to filtering expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30dca176-5229-4a18-b04e-01ce91a0eb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200028, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a boolean mask for filtering\n",
    "mask = df_tweets_raw_data['text'].str.contains(r'\\bvenezuel\\w*', flags=re.IGNORECASE, regex=True)\n",
    "\n",
    "# Applying the mask to create 'df_tweets_filtered'\n",
    "df_tweets_filtered = df_tweets_raw_data[mask]\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)\n",
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c457973b-6d31-4b37-8c62-6cf8d2c027f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43183, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the filtering expressions\n",
    "#filter_words = ['venezuelano', 'venezuelana', 'aporofobia', 'crise', 'discrimina√ß√£o', 'estigma', 'xenofobia', 'roraizuela', 'preconceito']\n",
    "filter_words = ['venezuelano', 'venezuelana', 'aporofobia', 'discrimina√ß√£o', 'estigma', 'xenofobia', 'roraizuela']\n",
    "\n",
    "# Creating a boolean mask for filtering\n",
    "mask = df_tweets_filtered['text'].str.contains('|'.join(filter_words), case=False)\n",
    "\n",
    "# Applying the mask to create 'df_tweets_filtered'\n",
    "df_tweets_filtered = df_tweets_filtered[mask]\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)\n",
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19db4718-37a5-4895-8f3c-cac12e4aa6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-13 15:01:06</td>\n",
       "      <td>2316329808</td>\n",
       "      <td>SrtaXiss</td>\n",
       "      <td>https://twitter.com/SrtaXiss/status/7865825419...</td>\n",
       "      <td>RT @BR_DeTodos200Mi: Grupo distribui comida pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-13 12:37:35</td>\n",
       "      <td>4876348647</td>\n",
       "      <td>ins_ana_</td>\n",
       "      <td>https://twitter.com/ins_ana_/status/7865464248...</td>\n",
       "      <td>RT @correio_dopovo: Roraima prepara gabinete d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-25 13:00:11</td>\n",
       "      <td>2858025838</td>\n",
       "      <td>ireneravachero3</td>\n",
       "      <td>https://twitter.com/ireneravachero3/status/790...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-13 16:13:46</td>\n",
       "      <td>457243275</td>\n",
       "      <td>vitor_CRVG</td>\n",
       "      <td>https://twitter.com/vitor_CRVG/status/78660082...</td>\n",
       "      <td>@Estadao queria saber se o diret√≥rio do @PSOLO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-23 15:20:13</td>\n",
       "      <td>2347256918</td>\n",
       "      <td>OthelinoSilva</td>\n",
       "      <td>https://twitter.com/OthelinoSilva/status/79021...</td>\n",
       "      <td>Oposi√ß√£o venezuelana assume ofensiva nas ruas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43178</th>\n",
       "      <td>2022-09-15 20:24:33</td>\n",
       "      <td>1097873314314403840</td>\n",
       "      <td>CanaldoRafinhaF</td>\n",
       "      <td>https://twitter.com/CanaldoRafinhaF/status/157...</td>\n",
       "      <td>Venezuelana que fugiu do seu Pa√≠s Natal por ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43179</th>\n",
       "      <td>2022-09-20 20:20:02</td>\n",
       "      <td>1039550079915487232</td>\n",
       "      <td>patchabalgo</td>\n",
       "      <td>https://twitter.com/patchabalgo/status/1572319...</td>\n",
       "      <td>RT @jairbolsonaro: - Assim como temos feito ao...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43180</th>\n",
       "      <td>2022-09-02 22:54:09</td>\n",
       "      <td>1515376066457649152</td>\n",
       "      <td>JorgeEd20505061</td>\n",
       "      <td>https://twitter.com/JorgeEd20505061/status/156...</td>\n",
       "      <td>RT @Rconstantino: N√∫mero de venezuelanos que f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43181</th>\n",
       "      <td>2022-09-03 20:20:43</td>\n",
       "      <td>587849537</td>\n",
       "      <td>RobertoMaynart</td>\n",
       "      <td>https://twitter.com/RobertoMaynart/status/1566...</td>\n",
       "      <td>RT @Rconstantino: N√∫mero de venezuelanos que f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43182</th>\n",
       "      <td>2022-09-20 22:41:15</td>\n",
       "      <td>701162766711787520</td>\n",
       "      <td>remescarvalho</td>\n",
       "      <td>https://twitter.com/remescarvalho/status/15723...</td>\n",
       "      <td>RT @jairbolsonaro: - Assim como temos feito ao...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43183 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at            author_id         username  \\\n",
       "0     2016-10-13 15:01:06           2316329808         SrtaXiss   \n",
       "1     2016-10-13 12:37:35           4876348647         ins_ana_   \n",
       "2     2016-10-25 13:00:11           2858025838  ireneravachero3   \n",
       "3     2016-10-13 16:13:46            457243275       vitor_CRVG   \n",
       "4     2016-10-23 15:20:13           2347256918    OthelinoSilva   \n",
       "...                   ...                  ...              ...   \n",
       "43178 2022-09-15 20:24:33  1097873314314403840  CanaldoRafinhaF   \n",
       "43179 2022-09-20 20:20:02  1039550079915487232      patchabalgo   \n",
       "43180 2022-09-02 22:54:09  1515376066457649152  JorgeEd20505061   \n",
       "43181 2022-09-03 20:20:43            587849537   RobertoMaynart   \n",
       "43182 2022-09-20 22:41:15   701162766711787520    remescarvalho   \n",
       "\n",
       "                                               tweet_url  \\\n",
       "0      https://twitter.com/SrtaXiss/status/7865825419...   \n",
       "1      https://twitter.com/ins_ana_/status/7865464248...   \n",
       "2      https://twitter.com/ireneravachero3/status/790...   \n",
       "3      https://twitter.com/vitor_CRVG/status/78660082...   \n",
       "4      https://twitter.com/OthelinoSilva/status/79021...   \n",
       "...                                                  ...   \n",
       "43178  https://twitter.com/CanaldoRafinhaF/status/157...   \n",
       "43179  https://twitter.com/patchabalgo/status/1572319...   \n",
       "43180  https://twitter.com/JorgeEd20505061/status/156...   \n",
       "43181  https://twitter.com/RobertoMaynart/status/1566...   \n",
       "43182  https://twitter.com/remescarvalho/status/15723...   \n",
       "\n",
       "                                                    text  \n",
       "0      RT @BR_DeTodos200Mi: Grupo distribui comida pa...  \n",
       "1      RT @correio_dopovo: Roraima prepara gabinete d...  \n",
       "2      E quanto a situa√ß√£o dos Venezuelanos,silencio ...  \n",
       "3      @Estadao queria saber se o diret√≥rio do @PSOLO...  \n",
       "4      Oposi√ß√£o venezuelana assume ofensiva nas ruas ...  \n",
       "...                                                  ...  \n",
       "43178  Venezuelana que fugiu do seu Pa√≠s Natal por ca...  \n",
       "43179  RT @jairbolsonaro: - Assim como temos feito ao...  \n",
       "43180  RT @Rconstantino: N√∫mero de venezuelanos que f...  \n",
       "43181  RT @Rconstantino: N√∫mero de venezuelanos que f...  \n",
       "43182  RT @jairbolsonaro: - Assim como temos feito ao...  \n",
       "\n",
       "[43183 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd7b9f3-f73c-4427-bbc2-f88dba9bfc38",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe51d6-4174-4832-9d2c-20b1753633e0",
   "metadata": {},
   "source": [
    "### Removing specific Unicode characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8053cb-d88b-490b-9072-b6593423edca",
   "metadata": {},
   "source": [
    "The dataset may need to be cleaned of invisible Unicode characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f15e4-6ed4-48ae-b37d-2ba56c3fdbf6",
   "metadata": {},
   "source": [
    "##### Detecting `U+2066` and `U+2069` characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f183cff-0aa9-4e51-af60-cfdf1dda639c",
   "metadata": {},
   "source": [
    "- [U+2066](https://www.compart.com/en/unicode/U+2066)\n",
    "- [U+2069](https://www.compart.com/en/unicode/U+2069)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543782b-fa73-4c34-aa36-5cbbaa2ea829",
   "metadata": {},
   "source": [
    "Please refer to:\n",
    "- [Python RegEx](https://www.w3schools.com/python/python_regex.asp)\n",
    "- [regex101](https://regex101.com/)\n",
    "- [RegExr](https://regexr.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569db1bb-d6ee-4eca-8383-5dfb522f35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character ‚Å¶: Count = 5\n",
      "Character ‚Å©: Count = 4\n"
     ]
    }
   ],
   "source": [
    "# Defining a function to detect specific Unicode characters\n",
    "def extract_unicode_characters(df, column_name):\n",
    "    unicode_chars = Counter()  # Initialize a Counter to store Unicode character counts\n",
    "\n",
    "    for value in df[column_name]:\n",
    "        if isinstance(value, str):\n",
    "            # Use RegEx to find non-ASCII characters (Unicode)\n",
    "#            non_ascii_chars = re.findall(r'[^\\x00-\\x7F]+', value)\n",
    "            # Use RegEx to find specific Unicode characters - adjust the expression accordingly\n",
    "            specific_unicode_chars = re.findall(r'[\\u2066\\u2069]', value)\n",
    "            unicode_chars.update(specific_unicode_chars)\n",
    "\n",
    "    return unicode_chars\n",
    "\n",
    "# Inspect the dataframe for specific Unicode characters\n",
    "unicode_counts = extract_unicode_characters(df_tweets_filtered, 'text')\n",
    "\n",
    "# Print the results\n",
    "for char, count in unicode_counts.items():\n",
    "    print(f'Character {char}: Count = {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638428bd-0874-4f13-b417-305c5ccab1b0",
   "metadata": {},
   "source": [
    "#### Removing `U+2066` and `U+2069` characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "795d7929-bb59-4417-87e5-1448a3662264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to remove specific Unicode characters\n",
    "def remove_specific_unicode(input_line):\n",
    "    # Using RegEx to replace specific Unicode characters - adjust the expression accordingly\n",
    "    cleaned_line = re.sub(r'[\\u2066\\u2069]', '', input_line)\n",
    "    return cleaned_line\n",
    "\n",
    "# Removing specific Unicode characters\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(remove_specific_unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c26537-d037-4167-ba31-841f90f209ff",
   "metadata": {},
   "source": [
    "### Replacing the `LF` character by a space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc0fd7-8f66-4320-b3fa-05443bb7f8d1",
   "metadata": {},
   "source": [
    "Some tweets, especially the retweeted ones, contain multiple lines of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "566a880a-7a43-4438-9455-36d5083678c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace the `LF` character by a space\n",
    "def remove_cr_lf(input_line):\n",
    "    # Using RegEx to replace LF by a space\n",
    "    cleaned_line = re.sub(r'\\n', ' ', input_line)\n",
    "    return cleaned_line\n",
    "\n",
    "# Applying the function to the 'text' column in your DataFrame\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(remove_cr_lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d9f80-d94b-4b79-b908-c1a7fedac755",
   "metadata": {},
   "source": [
    "### Replacing the `U+00A0` (No-Break Space) character by a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9e5601-e1fe-4964-9fee-615bb6d9440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace the `U+A0` character by a space\n",
    "def replace_no_break_space(input_line):\n",
    "    # Using RegEx to replace LF by a space\n",
    "    cleaned_line = re.sub(r'\\u00a0', ' ', input_line)\n",
    "    return cleaned_line\n",
    "\n",
    "# Applying the function to the 'text' column in your DataFrame\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(replace_no_break_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3138a6d-1946-41bb-a945-8b8ec93ce8a7",
   "metadata": {},
   "source": [
    "### Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d46b9d-f332-4161-b627-d94e7257198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to remove URLs\n",
    "def remove_urls(input_string):\n",
    "    modified_string = re.sub(r\"((http|https):\\/\\/)?([a-zA-Z0-9-]+\\.)+[a-zA-Z]{2,6}(\\/[a-zA-Z0-9-._~:\\/?#[\\]@!$&'()*+,;=]*)?\\/?\", '', input_string)\n",
    "    return modified_string\n",
    "\n",
    "# Removing URLs\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42dff06-9bd2-4dde-8dd4-e3713621c3b0",
   "metadata": {},
   "source": [
    "### Cleaning HTML entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f27b3fb-2a93-4c06-9dc7-249020c32ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_entities(input_line):\n",
    "    # Converting HTML entities to their corresponding characters\n",
    "    decoded_line = html.unescape(input_line)\n",
    "    # Removing HTML tags\n",
    "    cleaned_line = re.sub(r'<.*?>', '', decoded_line)\n",
    "    cleaned_line = re.sub(r'<', '', cleaned_line)\n",
    "    cleaned_line = re.sub(r'>', '', cleaned_line)\n",
    "    return cleaned_line\n",
    "\n",
    "# Applying the function to the 'text' column in your DataFrame\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(clean_html_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b6745-0cee-409a-a000-433d45eb147e",
   "metadata": {},
   "source": [
    "### Removing the preceding `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b02757-c2d5-416b-987e-2f74e8cb200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to remove preceding the dot\n",
    "def clean_text(input_line):\n",
    "    # Removing preceding dot\n",
    "    cleaned_line = re.sub(r'(^\\.)(?=[ #\\w+@])', '', input_line)\n",
    "    return cleaned_line\n",
    "\n",
    "# Applying the function to the 'text' column in your DataFrame\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf86646-b7f3-4f46-8980-aa0a09beb7af",
   "metadata": {},
   "source": [
    "### Dropping duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb5a78-4e47-431a-9bd2-95d7c7cbb517",
   "metadata": {},
   "source": [
    "#### Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058d083-6403-4413-8a8e-d56cf6b086d2",
   "metadata": {},
   "source": [
    "Retweets bear the following RegEx patterns at the beginning of the column `text`. They should be often dropped because they are duplicates of the original tweets. In the case of this study, though, the dataset may not include the original tweets because it is a 1% random sample. Therefore, only the first occurrence of the retweet is being kept.\n",
    "\n",
    "- \\bRT @\\w+\\s*:\n",
    "- \\brt @\\w+\\s*:\n",
    "- \\bRT @\\w+\\s*\n",
    "- \\bRT:\\s*\n",
    "- \\bRT\\s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc469663-ce28-4a9a-8826-4ea7362cbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'no_retweet' containing the contents of the column 'text' without any preceding 'RT @mentions:'\n",
    "df_tweets_filtered['no_retweet'] = df_tweets_filtered['text'].str.replace(r'\\bRT @\\w+\\s*:|\\brt @\\w+\\s*:|\\bRT @\\w+\\s*|\\bRT:\\s*|\\bRT\\s*', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f50a3ed7-953f-44ca-99d2-1fe601e54e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19301, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicate rows except the first occurrence based on 'no_mention'\n",
    "df_tweets_filtered.drop_duplicates(subset='no_retweet', keep='first', inplace=True)\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)\n",
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d40c1-7ff5-4696-9cac-d5cb94283f85",
   "metadata": {},
   "source": [
    "#### Duplicate tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b18f2-d620-440d-96b5-19cef9dcef8a",
   "metadata": {},
   "source": [
    "The dataset was build in a way that if a certain tweet had more than one photo, one copy of the tweet was included per unique photo. Since we are concerned with analysing just the text, those duplicates should be removed. Tweets that bear the same 'tweet_url' are duplicates - we are going to keep only the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed5a0b5e-d531-4e92-a16c-58d49cae2a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19301, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.drop_duplicates(subset='tweet_url', keep='first', inplace=True)\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)\n",
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7224b06-65a7-4102-a453-72fe54dfb05d",
   "metadata": {},
   "source": [
    "#### @mentioned tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8b3a2-54c3-4d84-8757-80b1bbcb7365",
   "metadata": {},
   "source": [
    "A few users @mention copies of tweets towards other specific users creating multiple copies of the same tweet - those duplicates should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bee2afc1-5c61-4212-9dc7-001aec574324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19281, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column 'no_mention' containing the contents of the column 'text' without any preceding @mentions\n",
    "df_tweets_filtered['no_mention'] = df_tweets_filtered['text'].str.replace(r'@\\w+\\s*', '', regex=True)\n",
    "\n",
    "# Drop duplicate rows except the first occurrence based on 'no_mention'\n",
    "df_tweets_filtered.drop_duplicates(subset='no_mention', keep='first', inplace=True)\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)\n",
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093e6da-d016-4cad-8c86-2a4f1a77feaf",
   "metadata": {},
   "source": [
    "#### Duplicate texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d87997c-3e18-4519-b3a0-7920115a7e76",
   "metadata": {},
   "source": [
    "Checking for identical posts in terms of content of the column `text` in order to eliminate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e9b40c-c54d-4bea-bc49-f332d9d01224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19281, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)\n",
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd0494-12e0-444f-ac77-a6bcc5cad7c5",
   "metadata": {},
   "source": [
    "## Inspecting and eliminating duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd3955-688a-444d-923e-a52f0fe4c6da",
   "metadata": {},
   "source": [
    "### Creating a DataFrame index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1008f565-23a6-41d5-8c31-42aa97873ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['df_index'] = df_tweets_filtered.index.astype(str).str.zfill(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4a608-0365-422f-ac7f-b764db80a724",
   "metadata": {},
   "source": [
    "### Sorting the DataFrame by the column `text` to enable duplicate detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8698aa58-9fe2-4681-8b1f-a712ea2edd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame by the 'text' column in ascending order\n",
    "df_tweets_filtered = df_tweets_filtered.sort_values(by='text', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128b9f3a-5604-4efa-82a5-780b9b1f7837",
   "metadata": {},
   "source": [
    "### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c99e0e64-6977-47d0-a15a-9ea1abce8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['df_index', 'text']].to_csv('tweets_emojified.tsv', sep='\\t', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4681e-92f2-4572-b779-7331edb0d058",
   "metadata": {},
   "source": [
    "### Inspecting a few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "306ecf98-3e6e-485e-93d4-57a445591ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:Filha de setubalenses est√° na linha da frente para \"resgatar a democracia\" venezuelana  \n"
     ]
    }
   ],
   "source": [
    "inspected_row = 1946\n",
    "print('text:' + df_tweets_filtered.loc[inspected_row, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154eacc-ab1f-4fb5-8bf6-d624e5dc0b9c",
   "metadata": {},
   "source": [
    "### Dropping identified duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0951020b-44c1-447f-a534-0cc8f6bd85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of indexes to drop\n",
    "indexes_to_drop = [\n",
    "    12718, \n",
    "    5241, \n",
    "    14957, \n",
    "    14969, \n",
    "    14973, \n",
    "    14977, \n",
    "    14985, \n",
    "    14993, \n",
    "    14997, \n",
    "    15005, \n",
    "    15012, \n",
    "    15020, \n",
    "    15021, \n",
    "    15022, \n",
    "    15025, \n",
    "    15033, \n",
    "    15034, \n",
    "    15038, \n",
    "    15050, \n",
    "    15054, \n",
    "    15057, \n",
    "    15061, \n",
    "    15064, \n",
    "    15092,  \n",
    "    12522, \n",
    "    17624, \n",
    "    17750, \n",
    "    17751, \n",
    "    14886, \n",
    "    14906, \n",
    "    14935, \n",
    "    14936, \n",
    "    14937, \n",
    "    14940, \n",
    "    14944, \n",
    "    14946, \n",
    "    14949, \n",
    "    14981, \n",
    "    14987, \n",
    "    14992, \n",
    "    15011, \n",
    "    15015, \n",
    "    15087, \n",
    "    15090, \n",
    "    15093, \n",
    "    15096, \n",
    "    15099, \n",
    "    14211, \n",
    "    15112, \n",
    "    14908, \n",
    "    17208, \n",
    "    1628, \n",
    "    3165, \n",
    "    438, \n",
    "    177, \n",
    "    149, \n",
    "    11121, \n",
    "    10950, \n",
    "    4982, \n",
    "    453, \n",
    "    456, \n",
    "    458, \n",
    "    470, \n",
    "    504, \n",
    "    508, \n",
    "    524, \n",
    "    562, \n",
    "    570, \n",
    "    575, \n",
    "    580, \n",
    "    606, \n",
    "    619, \n",
    "    658, \n",
    "    693, \n",
    "    782, \n",
    "    11380, \n",
    "    12400, \n",
    "    19190, \n",
    "    15798, \n",
    "    14408, \n",
    "    15607, \n",
    "    9585, \n",
    "    15846, \n",
    "    2062, \n",
    "    1362, \n",
    "    1363, \n",
    "    538, \n",
    "    6988, \n",
    "    10894, \n",
    "    3882, \n",
    "    1344, \n",
    "    3708, \n",
    "    1664, \n",
    "    1706, \n",
    "    1377, \n",
    "    6313, \n",
    "    12051, \n",
    "    2214, \n",
    "    3392, \n",
    "    67, \n",
    "    1245, \n",
    "    1786, \n",
    "    994, \n",
    "    8933, \n",
    "    1613, \n",
    "    15007, \n",
    "    894, \n",
    "    2380, \n",
    "    2378, \n",
    "    276, \n",
    "    293, \n",
    "    1372, \n",
    "    727, \n",
    "    3287, \n",
    "    3328, \n",
    "    3580, \n",
    "    7081, \n",
    "    11375, \n",
    "    18688, \n",
    "    18209, \n",
    "    2677, \n",
    "    11215, \n",
    "    2786, \n",
    "    5103, \n",
    "    3604, \n",
    "    3471, \n",
    "    3613, \n",
    "    165, \n",
    "    5967, \n",
    "    5032, \n",
    "    10109, \n",
    "    18245, \n",
    "    6598, \n",
    "    6036, \n",
    "    6320, \n",
    "    9658, \n",
    "    4411, \n",
    "    15590, \n",
    "    1117, \n",
    "    449, \n",
    "    1262, \n",
    "    3288, \n",
    "    3534, \n",
    "    620, \n",
    "    621, \n",
    "    4, \n",
    "    2111, \n",
    "    503, \n",
    "    519, \n",
    "    3181, \n",
    "    3151, \n",
    "    10147, \n",
    "    1607, \n",
    "    560, \n",
    "    579, \n",
    "    671, \n",
    "    673, \n",
    "    724, \n",
    "    777, \n",
    "    708, \n",
    "    1490, \n",
    "    4786, \n",
    "    1321, \n",
    "    742, \n",
    "    945, \n",
    "    5658, \n",
    "    14999, \n",
    "    15004, \n",
    "    2999, \n",
    "    2609, \n",
    "    2562, \n",
    "    13013, \n",
    "    7182, \n",
    "    4871, \n",
    "    13143, \n",
    "    14199, \n",
    "    837, \n",
    "    2772, \n",
    "    2793, \n",
    "    14587, \n",
    "    4763, \n",
    "    3136, \n",
    "    8252, \n",
    "    7388, \n",
    "    9628, \n",
    "    16699, \n",
    "    15839, \n",
    "    13703, \n",
    "    4542, \n",
    "    2210, \n",
    "    10839, \n",
    "    15636, \n",
    "    171, \n",
    "    3719, \n",
    "    2129, \n",
    "    1833, \n",
    "    8787, \n",
    "    2448, \n",
    "    3126, \n",
    "    1833, \n",
    "    1041, \n",
    "    1172, \n",
    "    713, \n",
    "    847, \n",
    "    665, \n",
    "    706, \n",
    "    703, \n",
    "    836, \n",
    "    631, \n",
    "    5021, \n",
    "    5074, \n",
    "    413, \n",
    "    2255, \n",
    "    1091, \n",
    "    1675, \n",
    "    4406, \n",
    "    9296\n",
    "]\n",
    "\n",
    "# Dropping the rows with the specified indexes\n",
    "df_tweets_filtered = df_tweets_filtered.drop(indexes_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71861080-78b2-4ae2-afdd-8640102974dd",
   "metadata": {},
   "source": [
    "### Sorting the DataFrame by the index to revert the DataFrame back to its original order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a8f5dec-7bdf-4c2f-bcf7-f740201a37ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame back to the original order by the index\n",
    "df_tweets_filtered = df_tweets_filtered.sort_index()\n",
    "df_tweets_filtered = df_tweets_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65c4b9f8-9c6b-4326-8a61-065a04a26e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "      <th>no_retweet</th>\n",
       "      <th>no_mention</th>\n",
       "      <th>df_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-13 15:01:06</td>\n",
       "      <td>2316329808</td>\n",
       "      <td>SrtaXiss</td>\n",
       "      <td>https://twitter.com/SrtaXiss/status/7865825419...</td>\n",
       "      <td>RT @BR_DeTodos200Mi: Grupo distribui comida pa...</td>\n",
       "      <td>Grupo distribui comida para venezuelanos nas ...</td>\n",
       "      <td>RT : Grupo distribui comida para venezuelanos ...</td>\n",
       "      <td>000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-13 12:37:35</td>\n",
       "      <td>4876348647</td>\n",
       "      <td>ins_ana_</td>\n",
       "      <td>https://twitter.com/ins_ana_/status/7865464248...</td>\n",
       "      <td>RT @correio_dopovo: Roraima prepara gabinete d...</td>\n",
       "      <td>Roraima prepara gabinete de emerg√™ncia para c...</td>\n",
       "      <td>RT : Roraima prepara gabinete de emerg√™ncia pa...</td>\n",
       "      <td>000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-25 13:00:11</td>\n",
       "      <td>2858025838</td>\n",
       "      <td>ireneravachero3</td>\n",
       "      <td>https://twitter.com/ireneravachero3/status/790...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "      <td>000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-13 16:13:46</td>\n",
       "      <td>457243275</td>\n",
       "      <td>vitor_CRVG</td>\n",
       "      <td>https://twitter.com/vitor_CRVG/status/78660082...</td>\n",
       "      <td>@Estadao queria saber se o diret√≥rio do @PSOLO...</td>\n",
       "      <td>@Estadao queria saber se o diret√≥rio do @PSOLO...</td>\n",
       "      <td>queria saber se o diret√≥rio do esta recebendo ...</td>\n",
       "      <td>000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-14 13:15:08</td>\n",
       "      <td>1944741320</td>\n",
       "      <td>Camisa13doGalo</td>\n",
       "      <td>https://twitter.com/Camisa13doGalo/status/7869...</td>\n",
       "      <td>R√≥mulo Otero celebra resultado e boa atua√ß√£o a...</td>\n",
       "      <td>R√≥mulo Otero celebra resultado e boa atua√ß√£o a...</td>\n",
       "      <td>R√≥mulo Otero celebra resultado e boa atua√ß√£o a...</td>\n",
       "      <td>000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19060</th>\n",
       "      <td>2022-09-20 00:40:39</td>\n",
       "      <td>1506118493938270208</td>\n",
       "      <td>Jmalvesdc</td>\n",
       "      <td>https://twitter.com/Jmalvesdc/status/157202289...</td>\n",
       "      <td>RT @BoicaIslene: Victor Lucchesi, exp√µe os cri...</td>\n",
       "      <td>Victor Lucchesi, exp√µe os crimes da ditadura ...</td>\n",
       "      <td>RT : Victor Lucchesi, exp√µe os crimes da ditad...</td>\n",
       "      <td>019276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19061</th>\n",
       "      <td>2022-09-05 22:32:00</td>\n",
       "      <td>2904143747</td>\n",
       "      <td>cjcastro45</td>\n",
       "      <td>https://twitter.com/cjcastro45/status/15669170...</td>\n",
       "      <td>RT @Pattypschmidt: Hoje conheci  Denisse . Uma...</td>\n",
       "      <td>Hoje conheci  Denisse . Uma das muitas Venezu...</td>\n",
       "      <td>RT : Hoje conheci  Denisse . Uma das muitas Ve...</td>\n",
       "      <td>019277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19062</th>\n",
       "      <td>2022-09-11 05:50:34</td>\n",
       "      <td>1547288191731900416</td>\n",
       "      <td>LimaFucuta</td>\n",
       "      <td>https://twitter.com/LimaFucuta/status/15688393...</td>\n",
       "      <td>@VEJA Cruz credo, o regime que o pt quer e apl...</td>\n",
       "      <td>@VEJA Cruz credo, o regime que o pt quer e apl...</td>\n",
       "      <td>Cruz credo, o regime que o pt quer e aplaude e...</td>\n",
       "      <td>019278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19063</th>\n",
       "      <td>2022-09-14 07:41:08</td>\n",
       "      <td>123496655</td>\n",
       "      <td>EMBRAC</td>\n",
       "      <td>https://twitter.com/EMBRAC/status/156995438618...</td>\n",
       "      <td>RT @DiarioPE: Justi√ßa argentina autoriza sa√≠da...</td>\n",
       "      <td>Justi√ßa argentina autoriza sa√≠da de parte da ...</td>\n",
       "      <td>RT : Justi√ßa argentina autoriza sa√≠da de parte...</td>\n",
       "      <td>019279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19064</th>\n",
       "      <td>2022-09-15 20:24:33</td>\n",
       "      <td>1097873314314403840</td>\n",
       "      <td>CanaldoRafinhaF</td>\n",
       "      <td>https://twitter.com/CanaldoRafinhaF/status/157...</td>\n",
       "      <td>Venezuelana que fugiu do seu Pa√≠s Natal por ca...</td>\n",
       "      <td>Venezuelana que fugiu do seu Pa√≠s Natal por ca...</td>\n",
       "      <td>Venezuelana que fugiu do seu Pa√≠s Natal por ca...</td>\n",
       "      <td>019280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19065 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               created_at            author_id         username  \\\n",
       "0     2016-10-13 15:01:06           2316329808         SrtaXiss   \n",
       "1     2016-10-13 12:37:35           4876348647         ins_ana_   \n",
       "2     2016-10-25 13:00:11           2858025838  ireneravachero3   \n",
       "3     2016-10-13 16:13:46            457243275       vitor_CRVG   \n",
       "4     2016-10-14 13:15:08           1944741320   Camisa13doGalo   \n",
       "...                   ...                  ...              ...   \n",
       "19060 2022-09-20 00:40:39  1506118493938270208        Jmalvesdc   \n",
       "19061 2022-09-05 22:32:00           2904143747       cjcastro45   \n",
       "19062 2022-09-11 05:50:34  1547288191731900416       LimaFucuta   \n",
       "19063 2022-09-14 07:41:08            123496655           EMBRAC   \n",
       "19064 2022-09-15 20:24:33  1097873314314403840  CanaldoRafinhaF   \n",
       "\n",
       "                                               tweet_url  \\\n",
       "0      https://twitter.com/SrtaXiss/status/7865825419...   \n",
       "1      https://twitter.com/ins_ana_/status/7865464248...   \n",
       "2      https://twitter.com/ireneravachero3/status/790...   \n",
       "3      https://twitter.com/vitor_CRVG/status/78660082...   \n",
       "4      https://twitter.com/Camisa13doGalo/status/7869...   \n",
       "...                                                  ...   \n",
       "19060  https://twitter.com/Jmalvesdc/status/157202289...   \n",
       "19061  https://twitter.com/cjcastro45/status/15669170...   \n",
       "19062  https://twitter.com/LimaFucuta/status/15688393...   \n",
       "19063  https://twitter.com/EMBRAC/status/156995438618...   \n",
       "19064  https://twitter.com/CanaldoRafinhaF/status/157...   \n",
       "\n",
       "                                                    text  \\\n",
       "0      RT @BR_DeTodos200Mi: Grupo distribui comida pa...   \n",
       "1      RT @correio_dopovo: Roraima prepara gabinete d...   \n",
       "2      E quanto a situa√ß√£o dos Venezuelanos,silencio ...   \n",
       "3      @Estadao queria saber se o diret√≥rio do @PSOLO...   \n",
       "4      R√≥mulo Otero celebra resultado e boa atua√ß√£o a...   \n",
       "...                                                  ...   \n",
       "19060  RT @BoicaIslene: Victor Lucchesi, exp√µe os cri...   \n",
       "19061  RT @Pattypschmidt: Hoje conheci  Denisse . Uma...   \n",
       "19062  @VEJA Cruz credo, o regime que o pt quer e apl...   \n",
       "19063  RT @DiarioPE: Justi√ßa argentina autoriza sa√≠da...   \n",
       "19064  Venezuelana que fugiu do seu Pa√≠s Natal por ca...   \n",
       "\n",
       "                                              no_retweet  \\\n",
       "0       Grupo distribui comida para venezuelanos nas ...   \n",
       "1       Roraima prepara gabinete de emerg√™ncia para c...   \n",
       "2      E quanto a situa√ß√£o dos Venezuelanos,silencio ...   \n",
       "3      @Estadao queria saber se o diret√≥rio do @PSOLO...   \n",
       "4      R√≥mulo Otero celebra resultado e boa atua√ß√£o a...   \n",
       "...                                                  ...   \n",
       "19060   Victor Lucchesi, exp√µe os crimes da ditadura ...   \n",
       "19061   Hoje conheci  Denisse . Uma das muitas Venezu...   \n",
       "19062  @VEJA Cruz credo, o regime que o pt quer e apl...   \n",
       "19063   Justi√ßa argentina autoriza sa√≠da de parte da ...   \n",
       "19064  Venezuelana que fugiu do seu Pa√≠s Natal por ca...   \n",
       "\n",
       "                                              no_mention df_index  \n",
       "0      RT : Grupo distribui comida para venezuelanos ...   000000  \n",
       "1      RT : Roraima prepara gabinete de emerg√™ncia pa...   000001  \n",
       "2      E quanto a situa√ß√£o dos Venezuelanos,silencio ...   000002  \n",
       "3      queria saber se o diret√≥rio do esta recebendo ...   000003  \n",
       "4      R√≥mulo Otero celebra resultado e boa atua√ß√£o a...   000005  \n",
       "...                                                  ...      ...  \n",
       "19060  RT : Victor Lucchesi, exp√µe os crimes da ditad...   019276  \n",
       "19061  RT : Hoje conheci  Denisse . Uma das muitas Ve...   019277  \n",
       "19062  Cruz credo, o regime que o pt quer e aplaude e...   019278  \n",
       "19063  RT : Justi√ßa argentina autoriza sa√≠da de parte...   019279  \n",
       "19064  Venezuelana que fugiu do seu Pa√≠s Natal por ca...   019280  \n",
       "\n",
       "[19065 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88deb2e9-5a63-4787-b38b-6ebe205a678d",
   "metadata": {},
   "source": [
    "## Exporting to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2797e-95a2-406a-b2bb-1ed78fcd940c",
   "metadata": {},
   "source": [
    "### JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d3724c9-f953-4e60-8977-b19d7b564e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['created_at', 'author_id', 'username', 'tweet_url', 'text']].to_json('tweets_filtered.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc0b3b-69c6-448e-a95d-ebab06b72184",
   "metadata": {},
   "source": [
    "### TSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2307eda9-8493-4089-9133-a2bc8afdf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['created_at', 'author_id', 'username', 'tweet_url', 'text']].to_csv('tweets_filtered.tsv', sep='\\t', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b81f047-6491-42c2-bd0c-bd00df802906",
   "metadata": {},
   "source": [
    "## Importing the Target Corpus into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52b1f421-01cd-450c-aa80-51fc6c2a3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered = pd.read_json('tweets_filtered.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c7d2247-0890-4fb2-8c6a-1b33c4c889d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-13 15:01:06</td>\n",
       "      <td>2316329808</td>\n",
       "      <td>SrtaXiss</td>\n",
       "      <td>https://twitter.com/SrtaXiss/status/7865825419...</td>\n",
       "      <td>RT @BR_DeTodos200Mi: Grupo distribui comida pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-13 12:37:35</td>\n",
       "      <td>4876348647</td>\n",
       "      <td>ins_ana_</td>\n",
       "      <td>https://twitter.com/ins_ana_/status/7865464248...</td>\n",
       "      <td>RT @correio_dopovo: Roraima prepara gabinete d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-25 13:00:11</td>\n",
       "      <td>2858025838</td>\n",
       "      <td>ireneravachero3</td>\n",
       "      <td>https://twitter.com/ireneravachero3/status/790...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos,silencio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-13 16:13:46</td>\n",
       "      <td>457243275</td>\n",
       "      <td>vitor_CRVG</td>\n",
       "      <td>https://twitter.com/vitor_CRVG/status/78660082...</td>\n",
       "      <td>@Estadao queria saber se o diret√≥rio do @PSOLO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-14 13:15:08</td>\n",
       "      <td>1944741320</td>\n",
       "      <td>Camisa13doGalo</td>\n",
       "      <td>https://twitter.com/Camisa13doGalo/status/7869...</td>\n",
       "      <td>R√≥mulo Otero celebra resultado e boa atua√ß√£o a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at   author_id         username  \\\n",
       "0 2016-10-13 15:01:06  2316329808         SrtaXiss   \n",
       "1 2016-10-13 12:37:35  4876348647         ins_ana_   \n",
       "2 2016-10-25 13:00:11  2858025838  ireneravachero3   \n",
       "3 2016-10-13 16:13:46   457243275       vitor_CRVG   \n",
       "4 2016-10-14 13:15:08  1944741320   Camisa13doGalo   \n",
       "\n",
       "                                           tweet_url  \\\n",
       "0  https://twitter.com/SrtaXiss/status/7865825419...   \n",
       "1  https://twitter.com/ins_ana_/status/7865464248...   \n",
       "2  https://twitter.com/ireneravachero3/status/790...   \n",
       "3  https://twitter.com/vitor_CRVG/status/78660082...   \n",
       "4  https://twitter.com/Camisa13doGalo/status/7869...   \n",
       "\n",
       "                                                text  \n",
       "0  RT @BR_DeTodos200Mi: Grupo distribui comida pa...  \n",
       "1  RT @correio_dopovo: Roraima prepara gabinete d...  \n",
       "2  E quanto a situa√ß√£o dos Venezuelanos,silencio ...  \n",
       "3  @Estadao queria saber se o diret√≥rio do @PSOLO...  \n",
       "4  R√≥mulo Otero celebra resultado e boa atua√ß√£o a...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98e5a920-7a7a-4a95-91f6-d3e5d71f55fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19065, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3561bd45-62e1-41e9-bd68-03d72345e162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at    datetime64[ns]\n",
       "author_id              int64\n",
       "username              object\n",
       "tweet_url             object\n",
       "text                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917bf454-dfe4-4a8b-b803-8edfad5a32fd",
   "metadata": {},
   "source": [
    "## Replacing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e19a96f-7fab-4f6b-85f4-60dd933485b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to format the hashtagged string\n",
    "def format_hashtagged_string(input_line):\n",
    "    # Defining a function to format the hashtagged string using RegEx\n",
    "    def process_hashtagged_string(s):\n",
    "            # Lowercase the string\n",
    "            s = s.lower()\n",
    "            # Add the appropriate prefixes and suffixes\n",
    "            s = f'HASHTAG{s}_h'\n",
    "            return s\n",
    "\n",
    "    # Use RegEx to find and process each hashtagged string\n",
    "    processed_line = re.sub(r'(#\\w+)', lambda match: process_hashtagged_string(match.group(1)), input_line)\n",
    "    return processed_line\n",
    "\n",
    "# Formatting the hashtagged strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(format_hashtagged_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268d8c1a-2600-4b18-a1c7-0141fdcd40ea",
   "metadata": {},
   "source": [
    "## Replacing emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478255c-a7a8-48f0-9608-999dc92464a4",
   "metadata": {},
   "source": [
    "### Demojifying the column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2341baec-2fa0-4ee8-82cf-1522257ab02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to demojify a string\n",
    "def demojify_line(input_line):\n",
    "    demojified_line = demoji.replace_with_desc(input_line, sep='<em>')\n",
    "    return demojified_line\n",
    "\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(demojify_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08405272-4072-4cbe-92c0-c221d3848181",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34ade362-d195-446a-ac16-cc88c5b6c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text']].to_csv('tweets_emojified1.tsv', sep='\\t', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ee493-3e57-4d46-817d-b7a4af0b0722",
   "metadata": {},
   "source": [
    "### Separating the demojified strings with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d55d111-b676-4569-89a0-a1c4ec2e57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to separate the demojified strings with spaces\n",
    "def preprocess_line(input_line):\n",
    "    # Add a space before the first delimiter '<em>', if it is not already preceded by one\n",
    "    preprocessed_line = re.sub(r'(?<! )<em>', ' <em>', input_line)\n",
    "    # Add a space after the first delimiter '<em>', if it is not already followed by one\n",
    "    preprocessed_line = re.sub(r'<em>(?! )', '<em> ', preprocessed_line)\n",
    "    return preprocessed_line\n",
    "\n",
    "# Separating the demojified strings with spaces\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(preprocess_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb282a-30a2-4401-80ac-305aa5f9d7c5",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa3fce08-90f6-4e6a-97f7-ae69517a3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text']].to_csv('tweets_emojified2.tsv', sep='\\t', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b2004-f565-44f9-9d43-31bf393170d8",
   "metadata": {},
   "source": [
    "### Formatting the demojified strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2357ac57-bf81-4377-9a21-90fb79d1fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to format the demojified string\n",
    "def format_demojified_string(input_line):\n",
    "    # Defining a function to format the demojified string using RegEx\n",
    "    def process_demojified_string(s):\n",
    "            # Lowercase the string\n",
    "            s = s.lower()\n",
    "            # Replace spaces and colons followed by a space with underscores\n",
    "            s = re.sub(r'(: )| ', '_', s)\n",
    "            # Add the appropriate prefixes and suffixes\n",
    "            s = f'EMOJI{s}e'\n",
    "            return s\n",
    "\n",
    "    # Use RegEx to find and process each demojified string\n",
    "    processed_line = re.sub(r'<em>(.*?)<em>', lambda match: process_demojified_string(match.group(1)), input_line)\n",
    "    return processed_line\n",
    "\n",
    "# Formatting the demojified strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(format_demojified_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743b0db-02a0-4e0b-b0b5-d6659960bc30",
   "metadata": {},
   "source": [
    "### Replacing the `pipe` character by the `-` character in the `text` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc943030-7448-4d4d-98b8-b03c40e113e2",
   "metadata": {},
   "source": [
    "Further on, a few columns of the dataframe are going to be exported into the file `tweets.txt` whose columns need to be delimited by the `pipe` character. Therefore, it is recommended that any occurrences of the `pipe` character in the `text` column are replaced by another character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab1c3584-ae80-41fc-b03a-4286a564a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace the 'pipe' character by the '-' character\n",
    "def replace_pipe_with_hyphen(input_string):\n",
    "    modified_string = re.sub(r'\\|', '-', input_string)\n",
    "    return modified_string\n",
    "\n",
    "# Replacing the 'pipe' character by the '-' character\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(replace_pipe_with_hyphen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d28f3-7d63-4c02-ba55-0dbc957a4291",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aab47cc6-5888-418a-8e4f-97daaf2ac3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text']].to_csv('tweets_emojified3.tsv', sep='\\t', index=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d4ca4-2999-47d3-ae97-b4f3a7599d84",
   "metadata": {},
   "source": [
    "## Tokenising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f950bc7-9ffa-4d96-9ce0-439643f90a55",
   "metadata": {},
   "source": [
    "Please refer to [What is tokenization in NLP?](https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c1d393e-e85d-48f8-93f2-d7dfec6a2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to tokenise a string\n",
    "def tokenise_string(input_line):\n",
    "    # Replace URLs with placeholders\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b'\n",
    "    placeholder = '<URL>'  # Choose a unique placeholder\n",
    "    urls = re.findall(url_pattern, input_line)\n",
    "    tokenised_line = re.sub(url_pattern, placeholder, input_line)  # Replace URLs with placeholders\n",
    "    \n",
    "    # Replace curly quotes with straight ones\n",
    "    tokenised_line = tokenised_line.replace('‚Äú', '\"').replace('‚Äù', '\"').replace(\"‚Äò\", \"'\").replace(\"‚Äô\", \"'\")\n",
    "    # Separate common punctuation marks with spaces\n",
    "    tokenised_line = re.sub(r'([.\\!?,\"\\'/()])', r' \\1 ', tokenised_line)\n",
    "    # Add a space before '#'\n",
    "    tokenised_line = re.sub(r'(?<!\\s)#', r' #', tokenised_line)  # Add a space before '#' if it is not already preceded by one\n",
    "    # Reduce extra spaces by a single space\n",
    "    tokenised_line = re.sub(r'\\s+', ' ', tokenised_line)\n",
    "    \n",
    "    # Replace the placeholders with the respective URLs\n",
    "    for url in urls:\n",
    "        tokenised_line = tokenised_line.replace(placeholder, url, 1)\n",
    "    \n",
    "    return tokenised_line\n",
    "\n",
    "# Tokenising the strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(tokenise_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad8cc4-bd36-4d7a-905e-55173081cd85",
   "metadata": {},
   "source": [
    "## Creating the files `file_index.txt` and `tweets.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a908ea-85cd-4ded-b752-2ce8ccee6f62",
   "metadata": {},
   "source": [
    "### Creating column `text_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e69b8a02-8d66-4227-838a-020f8e458225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_id'] = 't' + df_tweets_filtered.index.astype(str).str.zfill(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ecbc7-802a-4546-b770-bd94372e58f7",
   "metadata": {},
   "source": [
    "### Creating column `conversation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b26c71e4-6d0a-4f1f-a343-412755ec2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['author_id'] = df_tweets_filtered['author_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ad070c7-3caf-4eb8-8dfe-eba469fe0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['conversation'] = 'v:' + df_tweets_filtered['author_id'].str.replace('id_', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85be5b3-f3ec-4061-a9c7-6d29591a8efd",
   "metadata": {},
   "source": [
    "### Creating column `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc30acc9-8d7d-41ef-9e33-2367d4c1462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'created_at' to datetime format\n",
    "df_tweets_filtered['created_at'] = pd.to_datetime(df_tweets_filtered['created_at'])\n",
    "\n",
    "# Extract the date part (without time) into a new column 'date'\n",
    "df_tweets_filtered['date'] = df_tweets_filtered['created_at'].dt.date\n",
    "\n",
    "# Add the prefix 'd:' to the 'date' values\n",
    "df_tweets_filtered['date'] = 'd:' + df_tweets_filtered['date'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067eec7-aedb-4bba-8241-5d5d000f6226",
   "metadata": {},
   "source": [
    "### Creating column `text_url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a5dec9e-0791-4b40-b59e-b46b62d400ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_url'] = 'url:' + df_tweets_filtered['tweet_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c35b3-69bc-4039-aa13-6b496f81c729",
   "metadata": {},
   "source": [
    "### Creating column `user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5700d8af-3be8-4a60-bd3d-1ddf3df356ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['user'] = 'u:' + df_tweets_filtered['username']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d2a83-b1a0-4db7-b9d3-e6d91202402c",
   "metadata": {},
   "source": [
    "### Creating column `content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd9313bd-6cbe-487c-a152-de678559260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['content'] = 'c:' + df_tweets_filtered['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11872fa-2b44-4302-ab43-f98f64692eaf",
   "metadata": {},
   "source": [
    "### Reordering the created columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538070e-1838-454f-a761-549e2bd5bc36",
   "metadata": {},
   "source": [
    "Please refer to:\n",
    "- [Python - List Comprehension 1](https://www.w3schools.com/python/python_lists_comprehension.asp)\n",
    "- [Python - List Comprehension 2](https://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afc325f4-43c7-4ba8-b10f-130974d8c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns (we use list comprehension to create a list of all columns except 'text_id', 'variable', 'date' and 'text_url')\n",
    "df_tweets_filtered = df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url', 'user', 'content'] + [col for col in df_tweets_filtered.columns if col not in ['text_id', 'conversation', 'date', 'text_url', 'user', 'content']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1217907f-187c-4d64-a97a-e7a9c607f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>conversation</th>\n",
       "      <th>date</th>\n",
       "      <th>text_url</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t000000</td>\n",
       "      <td>v:2316329808</td>\n",
       "      <td>d:2016-10-13</td>\n",
       "      <td>url:https://twitter.com/SrtaXiss/status/786582...</td>\n",
       "      <td>u:SrtaXiss</td>\n",
       "      <td>c:RT @BR_DeTodos200Mi: Grupo distribui comida ...</td>\n",
       "      <td>2016-10-13 15:01:06</td>\n",
       "      <td>2316329808</td>\n",
       "      <td>SrtaXiss</td>\n",
       "      <td>https://twitter.com/SrtaXiss/status/7865825419...</td>\n",
       "      <td>RT @BR_DeTodos200Mi: Grupo distribui comida pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t000001</td>\n",
       "      <td>v:4876348647</td>\n",
       "      <td>d:2016-10-13</td>\n",
       "      <td>url:https://twitter.com/ins_ana_/status/786546...</td>\n",
       "      <td>u:ins_ana_</td>\n",
       "      <td>c:RT @correio_dopovo: Roraima prepara gabinete...</td>\n",
       "      <td>2016-10-13 12:37:35</td>\n",
       "      <td>4876348647</td>\n",
       "      <td>ins_ana_</td>\n",
       "      <td>https://twitter.com/ins_ana_/status/7865464248...</td>\n",
       "      <td>RT @correio_dopovo: Roraima prepara gabinete d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t000002</td>\n",
       "      <td>v:2858025838</td>\n",
       "      <td>d:2016-10-25</td>\n",
       "      <td>url:https://twitter.com/ireneravachero3/status...</td>\n",
       "      <td>u:ireneravachero3</td>\n",
       "      <td>c:E quanto a situa√ß√£o dos Venezuelanos , silen...</td>\n",
       "      <td>2016-10-25 13:00:11</td>\n",
       "      <td>2858025838</td>\n",
       "      <td>ireneravachero3</td>\n",
       "      <td>https://twitter.com/ireneravachero3/status/790...</td>\n",
       "      <td>E quanto a situa√ß√£o dos Venezuelanos , silenci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t000003</td>\n",
       "      <td>v:457243275</td>\n",
       "      <td>d:2016-10-13</td>\n",
       "      <td>url:https://twitter.com/vitor_CRVG/status/7866...</td>\n",
       "      <td>u:vitor_CRVG</td>\n",
       "      <td>c:@Estadao queria saber se o diret√≥rio do @PSO...</td>\n",
       "      <td>2016-10-13 16:13:46</td>\n",
       "      <td>457243275</td>\n",
       "      <td>vitor_CRVG</td>\n",
       "      <td>https://twitter.com/vitor_CRVG/status/78660082...</td>\n",
       "      <td>@Estadao queria saber se o diret√≥rio do @PSOLO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t000004</td>\n",
       "      <td>v:1944741320</td>\n",
       "      <td>d:2016-10-14</td>\n",
       "      <td>url:https://twitter.com/Camisa13doGalo/status/...</td>\n",
       "      <td>u:Camisa13doGalo</td>\n",
       "      <td>c:R√≥mulo Otero celebra resultado e boa atua√ß√£o...</td>\n",
       "      <td>2016-10-14 13:15:08</td>\n",
       "      <td>1944741320</td>\n",
       "      <td>Camisa13doGalo</td>\n",
       "      <td>https://twitter.com/Camisa13doGalo/status/7869...</td>\n",
       "      <td>R√≥mulo Otero celebra resultado e boa atua√ß√£o a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19060</th>\n",
       "      <td>t019060</td>\n",
       "      <td>v:1506118493938270208</td>\n",
       "      <td>d:2022-09-20</td>\n",
       "      <td>url:https://twitter.com/Jmalvesdc/status/15720...</td>\n",
       "      <td>u:Jmalvesdc</td>\n",
       "      <td>c:RT @BoicaIslene: Victor Lucchesi , exp√µe os ...</td>\n",
       "      <td>2022-09-20 00:40:39</td>\n",
       "      <td>1506118493938270208</td>\n",
       "      <td>Jmalvesdc</td>\n",
       "      <td>https://twitter.com/Jmalvesdc/status/157202289...</td>\n",
       "      <td>RT @BoicaIslene: Victor Lucchesi , exp√µe os cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19061</th>\n",
       "      <td>t019061</td>\n",
       "      <td>v:2904143747</td>\n",
       "      <td>d:2022-09-05</td>\n",
       "      <td>url:https://twitter.com/cjcastro45/status/1566...</td>\n",
       "      <td>u:cjcastro45</td>\n",
       "      <td>c:RT @Pattypschmidt: Hoje conheci Denisse . Um...</td>\n",
       "      <td>2022-09-05 22:32:00</td>\n",
       "      <td>2904143747</td>\n",
       "      <td>cjcastro45</td>\n",
       "      <td>https://twitter.com/cjcastro45/status/15669170...</td>\n",
       "      <td>RT @Pattypschmidt: Hoje conheci Denisse . Uma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19062</th>\n",
       "      <td>t019062</td>\n",
       "      <td>v:1547288191731900416</td>\n",
       "      <td>d:2022-09-11</td>\n",
       "      <td>url:https://twitter.com/LimaFucuta/status/1568...</td>\n",
       "      <td>u:LimaFucuta</td>\n",
       "      <td>c:@VEJA Cruz credo , o regime que o pt quer e ...</td>\n",
       "      <td>2022-09-11 05:50:34</td>\n",
       "      <td>1547288191731900416</td>\n",
       "      <td>LimaFucuta</td>\n",
       "      <td>https://twitter.com/LimaFucuta/status/15688393...</td>\n",
       "      <td>@VEJA Cruz credo , o regime que o pt quer e ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19063</th>\n",
       "      <td>t019063</td>\n",
       "      <td>v:123496655</td>\n",
       "      <td>d:2022-09-14</td>\n",
       "      <td>url:https://twitter.com/EMBRAC/status/15699543...</td>\n",
       "      <td>u:EMBRAC</td>\n",
       "      <td>c:RT @DiarioPE: Justi√ßa argentina autoriza sa√≠...</td>\n",
       "      <td>2022-09-14 07:41:08</td>\n",
       "      <td>123496655</td>\n",
       "      <td>EMBRAC</td>\n",
       "      <td>https://twitter.com/EMBRAC/status/156995438618...</td>\n",
       "      <td>RT @DiarioPE: Justi√ßa argentina autoriza sa√≠da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19064</th>\n",
       "      <td>t019064</td>\n",
       "      <td>v:1097873314314403840</td>\n",
       "      <td>d:2022-09-15</td>\n",
       "      <td>url:https://twitter.com/CanaldoRafinhaF/status...</td>\n",
       "      <td>u:CanaldoRafinhaF</td>\n",
       "      <td>c:Venezuelana que fugiu do seu Pa√≠s Natal por ...</td>\n",
       "      <td>2022-09-15 20:24:33</td>\n",
       "      <td>1097873314314403840</td>\n",
       "      <td>CanaldoRafinhaF</td>\n",
       "      <td>https://twitter.com/CanaldoRafinhaF/status/157...</td>\n",
       "      <td>Venezuelana que fugiu do seu Pa√≠s Natal por ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19065 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_id           conversation          date  \\\n",
       "0      t000000           v:2316329808  d:2016-10-13   \n",
       "1      t000001           v:4876348647  d:2016-10-13   \n",
       "2      t000002           v:2858025838  d:2016-10-25   \n",
       "3      t000003            v:457243275  d:2016-10-13   \n",
       "4      t000004           v:1944741320  d:2016-10-14   \n",
       "...        ...                    ...           ...   \n",
       "19060  t019060  v:1506118493938270208  d:2022-09-20   \n",
       "19061  t019061           v:2904143747  d:2022-09-05   \n",
       "19062  t019062  v:1547288191731900416  d:2022-09-11   \n",
       "19063  t019063            v:123496655  d:2022-09-14   \n",
       "19064  t019064  v:1097873314314403840  d:2022-09-15   \n",
       "\n",
       "                                                text_url               user  \\\n",
       "0      url:https://twitter.com/SrtaXiss/status/786582...         u:SrtaXiss   \n",
       "1      url:https://twitter.com/ins_ana_/status/786546...         u:ins_ana_   \n",
       "2      url:https://twitter.com/ireneravachero3/status...  u:ireneravachero3   \n",
       "3      url:https://twitter.com/vitor_CRVG/status/7866...       u:vitor_CRVG   \n",
       "4      url:https://twitter.com/Camisa13doGalo/status/...   u:Camisa13doGalo   \n",
       "...                                                  ...                ...   \n",
       "19060  url:https://twitter.com/Jmalvesdc/status/15720...        u:Jmalvesdc   \n",
       "19061  url:https://twitter.com/cjcastro45/status/1566...       u:cjcastro45   \n",
       "19062  url:https://twitter.com/LimaFucuta/status/1568...       u:LimaFucuta   \n",
       "19063  url:https://twitter.com/EMBRAC/status/15699543...           u:EMBRAC   \n",
       "19064  url:https://twitter.com/CanaldoRafinhaF/status...  u:CanaldoRafinhaF   \n",
       "\n",
       "                                                 content          created_at  \\\n",
       "0      c:RT @BR_DeTodos200Mi: Grupo distribui comida ... 2016-10-13 15:01:06   \n",
       "1      c:RT @correio_dopovo: Roraima prepara gabinete... 2016-10-13 12:37:35   \n",
       "2      c:E quanto a situa√ß√£o dos Venezuelanos , silen... 2016-10-25 13:00:11   \n",
       "3      c:@Estadao queria saber se o diret√≥rio do @PSO... 2016-10-13 16:13:46   \n",
       "4      c:R√≥mulo Otero celebra resultado e boa atua√ß√£o... 2016-10-14 13:15:08   \n",
       "...                                                  ...                 ...   \n",
       "19060  c:RT @BoicaIslene: Victor Lucchesi , exp√µe os ... 2022-09-20 00:40:39   \n",
       "19061  c:RT @Pattypschmidt: Hoje conheci Denisse . Um... 2022-09-05 22:32:00   \n",
       "19062  c:@VEJA Cruz credo , o regime que o pt quer e ... 2022-09-11 05:50:34   \n",
       "19063  c:RT @DiarioPE: Justi√ßa argentina autoriza sa√≠... 2022-09-14 07:41:08   \n",
       "19064  c:Venezuelana que fugiu do seu Pa√≠s Natal por ... 2022-09-15 20:24:33   \n",
       "\n",
       "                 author_id         username  \\\n",
       "0               2316329808         SrtaXiss   \n",
       "1               4876348647         ins_ana_   \n",
       "2               2858025838  ireneravachero3   \n",
       "3                457243275       vitor_CRVG   \n",
       "4               1944741320   Camisa13doGalo   \n",
       "...                    ...              ...   \n",
       "19060  1506118493938270208        Jmalvesdc   \n",
       "19061           2904143747       cjcastro45   \n",
       "19062  1547288191731900416       LimaFucuta   \n",
       "19063            123496655           EMBRAC   \n",
       "19064  1097873314314403840  CanaldoRafinhaF   \n",
       "\n",
       "                                               tweet_url  \\\n",
       "0      https://twitter.com/SrtaXiss/status/7865825419...   \n",
       "1      https://twitter.com/ins_ana_/status/7865464248...   \n",
       "2      https://twitter.com/ireneravachero3/status/790...   \n",
       "3      https://twitter.com/vitor_CRVG/status/78660082...   \n",
       "4      https://twitter.com/Camisa13doGalo/status/7869...   \n",
       "...                                                  ...   \n",
       "19060  https://twitter.com/Jmalvesdc/status/157202289...   \n",
       "19061  https://twitter.com/cjcastro45/status/15669170...   \n",
       "19062  https://twitter.com/LimaFucuta/status/15688393...   \n",
       "19063  https://twitter.com/EMBRAC/status/156995438618...   \n",
       "19064  https://twitter.com/CanaldoRafinhaF/status/157...   \n",
       "\n",
       "                                                    text  \n",
       "0      RT @BR_DeTodos200Mi: Grupo distribui comida pa...  \n",
       "1      RT @correio_dopovo: Roraima prepara gabinete d...  \n",
       "2      E quanto a situa√ß√£o dos Venezuelanos , silenci...  \n",
       "3      @Estadao queria saber se o diret√≥rio do @PSOLO...  \n",
       "4      R√≥mulo Otero celebra resultado e boa atua√ß√£o a...  \n",
       "...                                                  ...  \n",
       "19060  RT @BoicaIslene: Victor Lucchesi , exp√µe os cr...  \n",
       "19061  RT @Pattypschmidt: Hoje conheci Denisse . Uma ...  \n",
       "19062  @VEJA Cruz credo , o regime que o pt quer e ap...  \n",
       "19063  RT @DiarioPE: Justi√ßa argentina autoriza sa√≠da...  \n",
       "19064  Venezuelana que fugiu do seu Pa√≠s Natal por ca...  \n",
       "\n",
       "[19065 rows x 11 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f23e3-bc12-4150-8bf1-557184b40d1b",
   "metadata": {},
   "source": [
    "### Creating the file `file_index.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "199bbbe5-a366-4fde-9314-f0de3d49c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url']].to_csv('file_index.txt', sep=' ', index=False, header=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd415c21-39dc-4083-9632-e5cd92fa6948",
   "metadata": {},
   "source": [
    "### Creating the file `tweets.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5445fc96-0b9f-4283-80b3-09b1bddeab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder tweets created!\n"
     ]
    }
   ],
   "source": [
    "folder = 'tweets'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "    print(f'Folder {folder} created!')\n",
    "except FileExistsError:\n",
    "    print(f'Folder {folder} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de49e26-5efe-472f-9952-cef41fcda082",
   "metadata": {},
   "source": [
    "Note: The parameters `doublequote=False` and `escapechar=' '` are required to avoid that the column content is doublequoted with '\"' in sentences that use characters that need to be escaped such as double quote '\"' itself - this causes a malformed response from TreeTagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b566e03-56e4-44a8-8558-b6e940bb6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'user', 'content']].to_csv(f'{folder}/tweets.txt', sep='|', index=False, header=False, encoding='utf-8', lineterminator='\\n', doublequote=False, escapechar=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f769843-4ff9-4436-a2e0-d61e2c391e9d",
   "metadata": {},
   "source": [
    "## Tagging with TreeTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3877be9-6317-42ee-8e8d-c15c48f77996",
   "metadata": {},
   "source": [
    "- On Visual Studio Code (VS Code), open the folder where your project is located with `Open Folder...`\n",
    "- Open a WSL Ubuntu Terminal on VS Code\n",
    "- **Important**: Activate the `my_env` Python environment by executing `source \"$HOME\"/my_env/bin/activate`\n",
    "- Proceed as indicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720724ab-5e77-4e9e-b05a-24cf73259cd0",
   "metadata": {},
   "source": [
    "Purpose: Annotate the texts in `tweets/tweets.txt` with part-of-speech and lemma information.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `tweets/tweets.txt`\n",
    "- Output\n",
    "    - `tweets/tagged.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005cc09-f5ef-454f-9b74-4d7ca9fe4f10",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash treetagging.sh\n",
    "--- treetagging t000000 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000001 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000002 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "--- treetagging t000003 / t018205 ---\n",
    "        reading parameters ...\n",
    "        tagging ...\n",
    "         finished.\n",
    "<omitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b07f2-9cfa-47bd-9d05-42a44f487746",
   "metadata": {},
   "source": [
    "## Processing `CL_St1_Ph11_Mariana.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f35d6-6e8d-418d-a0c3-ffc33c5cd2a4",
   "metadata": {},
   "source": [
    "Run the solution `CL_St1_Ph11_Mariana.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0060ba-d01c-4e48-a353-8c9ba0fc456e",
   "metadata": {},
   "source": [
    "## Processing `tokenstypes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93351bf2-3457-4b47-8a47-7ff13c4e0e1a",
   "metadata": {},
   "source": [
    "Purpose: Capture the content tokens (specific occurrences of words) and the content types (general concept of words) from `tweets/tagged.txt`.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `tweets/tagged.txt`\n",
    "- Output\n",
    "    - `tweets/tokens.txt`\n",
    "    - `tweets/types.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddc717-8ff2-4f38-ae10-8d6616de6a6c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash tokenstypes.sh\n",
    "--- tokenstypes t000000 / 18206 ---\n",
    "--- tokenstypes t000001 / 18206 ---\n",
    "--- tokenstypes t000002 / 18206 ---\n",
    "--- tokenstypes t000003 / 18206 ---\n",
    "--- tokenstypes t000004 / 18206 ---\n",
    "--- tokenstypes t000005 / 18206 ---\n",
    "<omitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef598329-fb5a-4b07-8799-b2bbb55847f1",
   "metadata": {},
   "source": [
    "## Processing `toplemmas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce5796-0434-44d5-88e2-8f934a6cebc8",
   "metadata": {},
   "source": [
    "Purpose: Determine the 1.000 top lemmas. **Important**: This process requires manual inspection. Non-meaningful lemmas should be excluded by updating `stoplist.sed` and reiterating the processing. Proceed as indicated in this [video tutorial](https://youtu.be/4UIPpdoozP0?si=_3md9w79njZY86PE), from 20:05 to 25:16.\n",
    "- Input\n",
    "    - `tweets/types.txt`\n",
    "    - `stoplist.sed`: List of rules that allows the exclusion of a certain lemmas\n",
    "- Output\n",
    "    - `selectedwords` = `var_index.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0fc8e-73e2-4e2d-9e2f-73068e4132fc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash toplemmas.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0a4675-5067-4e8b-8ca8-baf9f1b915c1",
   "metadata": {},
   "source": [
    "## Processing `sas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d158b2-73d7-477e-a7a7-2b87216a19ae",
   "metadata": {},
   "source": [
    "Purpose: Prepare input data for processing in SAS.\n",
    "- Input\n",
    "    - `tweets/types.txt`\n",
    "    - `selectedwords`\n",
    "    - `file_index.txt`\n",
    "- Output\n",
    "    - `columns`\n",
    "    - `sas/data.txt`\n",
    "    - `sas/dates.txt`\n",
    "    - `sas/wcount.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d250d29-861c-41a6-9793-e0df758100e0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash sas.sh\n",
    "--- v000001 ---\n",
    "--- v000002 ---\n",
    "--- v000003 ---\n",
    "--- v000004 ---\n",
    "--- v000005 ---\n",
    "<omitted>\n",
    "--- v001000 ---\n",
    "[nltk_data] Downloading package punkt to /home/eyamrog/nltk_data...\n",
    "[nltk_data]   Package punkt is already up-to-date!\n",
    "Word counts written to sas/wcount.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8087ea-ffd4-43b9-8eda-4444b931c319",
   "metadata": {},
   "source": [
    "## Processing `datamatrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4374f48-04b6-48af-a31d-125ef0e85972",
   "metadata": {},
   "source": [
    "Purpose: Prepares input data for calculating the correlation matrix.\n",
    "- Input\n",
    "    - `file_index.txt`\n",
    "    - `columns`\n",
    "    - `selectedwords`\n",
    "- Output\n",
    "    - `file_ids.txt`\n",
    "    - `data.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23925f09-05ef-44a5-ba48-78cac1dedc76",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash datamatrix.sh\n",
    "--- v000001 ---\n",
    "--- v000002 ---\n",
    "--- v000003 ---\n",
    "--- v000004 ---\n",
    "--- v000005 ---\n",
    "<omitted>\n",
    "--- v001000 ---\n",
    "--- data.csv ...---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130e8f0-a7e5-4f6e-b427-090f7cda4856",
   "metadata": {},
   "source": [
    "## Processing `correlationmatrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bddbb87-b4de-4c41-8177-b2f677d803b6",
   "metadata": {},
   "source": [
    "Purpose: Calculates the correlation matrix.\n",
    "- Input\n",
    "    - `data.csv`\n",
    "- Output\n",
    "    - `correlation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42927846-5d87-4f5f-8ce6-8beb4ef733a4",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash correlationmatrix.sh\n",
    "--- python correlation ... ---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9203f-e9e1-4a73-8bed-7dec1ad8617e",
   "metadata": {},
   "source": [
    "## Processing `formats`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69517100-c28d-44ba-90a7-37988e3df8ad",
   "metadata": {},
   "source": [
    "Purpose: Prepare input data for processing in SAS.\n",
    "- Input\n",
    "    - `data.csv`\n",
    "    - `selectedwords`\n",
    "- Output\n",
    "    - `sas/corr.txt`\n",
    "    - `sas/word_labels_format.sas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9b02f-fd33-4ff2-bf57-463fac9743e6",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash formats.sh\n",
    "--- sas/sas/corr.txt ---\n",
    "--- sas/word_labels_format.sas ---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb5b2a-e203-4b3e-80a9-86b10fc0253c",
   "metadata": {},
   "source": [
    "## Processing the statistical procedures on SAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc9cd8-cd80-41d2-8209-f0a363fd9ab2",
   "metadata": {},
   "source": [
    "- Log in to your [SAS OnDemand for Academics](https://welcome.oda.sas.com/) account\n",
    "- Proceed as indicated in this [video tutorial](https://youtu.be/I3u9zD3jyOA?si=68uIKVc2iusGG2KY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed501c0-f6b1-4050-a4eb-a486bb73c036",
   "metadata": {},
   "source": [
    "## Processing `examples`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cef7d2-d981-4d52-b340-3c55ffe0699a",
   "metadata": {},
   "source": [
    "Purpose: Extract examples for analysis.\n",
    "- Input\n",
    "    - `sas/output_\"$project\"/loadtable.html`\n",
    "    - `sas/output_\"$project\"/\"$project\"_scores.tsv`\n",
    "    - `sas/output_\"$project\"/\"$project\"_scores_only.tsv`\n",
    "- Output\n",
    "    - `examples/factors`\n",
    "    - `example files`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf820c-016d-4940-940c-82a587f2c22b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ bash examples.sh\n",
    "6780\n",
    "1246\n",
    "698\n",
    "123\n",
    "--- examples f1pos ---\n",
    "--- factor 1 pos # 000001 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000002 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000003 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000004 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "--- factor 1 pos # 000005 ---\n",
    "tr: warning: an unescaped backslash at end of string is not portable\n",
    "<ommitted>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38617b-0487-4ba2-b619-d9b78aba9f2c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf501e4a-1193-4999-bdc0-88c08d2840f7",
   "metadata": {},
   "source": [
    "Right-click on the link and choose `Save link as` to download the corresponding file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73ba45-9d6c-4578-b14e-c80c3ccaafe4",
   "metadata": {},
   "source": [
    "- [CL_St1_Mariana_Results.tar.gz](https://pucsp-my.sharepoint.com/:u:/g/personal/ra00341729_pucsp_edu_br/EU1-gvN-4pRDqIuGkPWHry4B6dJ7dY6gWqaKcydFL7evvA?e=AGpfTJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5b60f-6f20-4c7a-ac16-7d0c04c86126",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Proceed as follows to extract the files from the archive `CL_St1_Mariana_Results.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4de1b-c441-4d75-b3f4-deaf61a63192",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ tar xzvf CL_St1_Mariana_Results.tar.gz\n",
    "<omitted>\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb169464-4f29-4513-b272-46f201deff17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
